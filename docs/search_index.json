[["index.html", "index 1 시작에 앞서", " index mr21percent 2022-07-28 1 시작에 앞서 이거 읽으시는 분들 시계열 분석은 R이나 eviews로 하세요 …..제발 아직 제대로된 python 시계열 패키지가 존재하지 않는거 같습니다. statsmodels에서는 ARCH GARCH의 경우 지원하지 않고 있습니다. 대부분 관심도가 높은 상태공간모형, VAR에 집중하고 있다고 합니다. 후에, 파이썬으로 해당 내용들을 전부 정리를 마치고 난 뒤에 R 코드를 추가할 계획은 있습니다만, python만 해도 너무 양이 방대해 언제 될지는 모릅니다. "],["안정적-시계열모형의-추정과-예측.html", "2 안정적 시계열모형의 추정과 예측 2.1 시작에 앞서 python을 사용하기 위한 설정 2.2 일반적인 시계열 분석 과정의 이해 2.3 기초 개념 2.4 자기회귀모형 2.5 이동평균 모형 2.6 q-차 이동평균모형(MA(q)모형) 2.7 자기회귀 - 이동평균모형(ARMA(p,q) models) 2.8 적정 ARMA(p,q)모형 선정 절차 - Diagnostic Checking 2.9 ARMA 모형의 예측", " 2 안정적 시계열모형의 추정과 예측 2.1 시작에 앞서 python을 사용하기 위한 설정 다음은 python을 불러오기 위한 것입니다. 본인의 파이썬 경로를 넣으실 수도 있겠지만, 편의를 위하여 포함되어 있는 파일을 사용하시길 추천드립니다. library(&quot;reticulate&quot;) use_python(&quot;../python&quot;) import pandas as pd import numpy as np import statsmodels as sm import yfinance as yf import matplotlib.pyplot as plt 2.2 일반적인 시계열 분석 과정의 이해 단일 시계열로는 예측이 되지 않을 수 있다. 여러개의 시계열을 도입할 경우 서로 크기가 상이할 수 있으므로 각각 시계열의 표본평균을 제하고 이를 표본표준편차로 나누어 정규화하여 비교하는 것이 유용하다. 안정적 시계열이라는 것을 가정하자. 안정적 시계열이란 시간이 경과함에도 불구하고 평균이 일정하며 특정 시점에서 시계열의 값이 평균에서 벗어날 수는 있지만, 시간이 지남에 따라 평균으로 회귀하는 특성을 가진다. 안정적 시계열임을 어떻게 확인할 수 있을까? 단위근 검정 으로 확인이 가능하다. 2.3 기초 개념 2.3.1 확률과정 2.3.1.1 확률 변수 (random variable 또는 stochastic variable) \\(0 &lt; Pr(x=r) &lt; 1\\) 을 만족하는 임의의 정수 r이 최소 하나가 존재하는 경우 \\(x\\)를 지칭한다 2.3.1.2 확률 과정 (stochastic process) 적절한 확률공간에서 정의되는 \\(x\\)를 t-시점마다 기록한 일련의 확률변수를 지칭하며 보통 \\({x_t}\\)로 표시한다. \\(\\{x_t\\}^T_1 = (x_1, x_2, \\cdots, x_T)\\)를 확률변수의 모집단 \\(\\{x_t\\}^\\infty_{-\\infty}\\) 중 \\(T\\)개의 특정한 실현값(realization)이라고 하자.모든 실현 가능한 값들로 구성된 확률변수의 모집단을 확률과정의 ‘앙상블(ensemble)’ 이라고 부른다. 일반적으로 \\(T\\)개의 실현값으로 구성된 확률과정은 \\(T\\)-차원의 결합확률분포 \\(F(x_1,x_2,\\cdots,x_T)\\) 로 기술할 수 있다. 결합확률분포의 모든 모멘트(평균, 분산 등)을 단 한 번의 실현값 x_t로 부터 추론하는 것은 불가능하기 때문에 확률과정을 이야기할 때는 보통 ‘안정성’(stationarity)이라는 가정을 도입하게 된다. 2.3.2 안정성, 자기공분산 및 자기 상관 2.3.2.1 (약)안정성 다음 조건을 만족하는 경우 시계열 \\(x_t\\)는 ‘약안정적’(weakly stationary 또는 covariance stationary)라고 한다. \\[ E(x_t)=\\int^\\infty_{-\\infty}x_tf(x_t)dx_t = \\mu &lt; \\infty \\qquad \\forall t \\\\ Var(x_t) = E(x_t=\\mu)^2 = \\int^\\infty_{-\\infty}(x_t-\\mu)^2f(x_t)dx_t = \\gamma_0 &lt; \\infty \\qquad \\forall t \\\\ Cov(x_t, x_{t-k}) = E(x_t-\\mu)(x_{t-k}-\\mu) = \\gamma_k &lt; \\infty \\qquad \\forall t,k \\] 단, \\(f(x_t)\\)는 확률변수 \\(x_t\\) 의 비조건부밀도함수를 나타낸다. 중요한 점은 일차 및 이차 모멘트들이 ‘시간 가변적이지 않은 유한한 상수’일 때 \\(x_t\\)를 안정적이라고 한다는 것입니다. 2.3.2.2 자기공분산 (autocovariance) [\\(\\gamma_k\\)] 공분산(covariance)이 두 변수사이의 움직임을 측정하는데 반하여 \\(k\\)-시점 떨어진 자기자신의 과거값과의 움직임을 예측하는데 쓰인다. 관측치들 사이의 거리가 과거 \\(k\\)-시점이건, 미래로 \\(k\\)-시점이던 관계가 없기 때문에 \\(\\gamma_k = \\gamma_{-k} = Cov(x_t, x_{t+k})\\)이 성립한다. ‘표본자기공분산’(\\(\\hat{\\gamma_k}\\))은 다음과 같이 계산할 수 있다. \\[ \\hat{\\gamma_k} = (1/T)\\Sigma^{T-k}_{t=1}(x_t - \\bar{x})(x_{t+k} - \\bar{x}) \\] 2.3.2.3 자기상관계수 (autocorrelation) [\\(\\rho_k\\)] 자기공분산값은 변수를 어떠한 단위로 측정하는가에 따라 크기가 달라지기 때문에 \\(\\gamma_k\\)를 \\(\\gamma_0\\), 즉 분산으로 나눈 ‘자기상관계수’ \\(\\rho_k\\)를 계산한다. \\[ \\rho_k = corr(x_t,x_{t-k}) = \\frac{\\gamma_k}{\\gamma_0} \\] 자기상관계수를 각각의 \\(k\\)에 대한 함수로 표시한 것을 ‘자기상관함수’(ACF)라고 하고 ‘correlogram’이라고도 부른다. ‘표본자기상관계수’(\\(\\hat{\\rho_k}\\))는 다음과 같이 계산한다. \\[ \\hat{\\rho_k} = \\frac{\\Sigma^T_{t=k+1}(x_t-\\bar{x})(x_{t-k}-\\bar{x})}{\\Sigma^T_{t=1}(x_t-\\bar{x})^2} \\] 2.3.2.4 강안정성 확률과정의 특성이 기준시점의 변화에 영향을 전혀 받지 않는 경우 이 과정을 ‘강안정적’(strictly stationary 또는 strongly stationary)라고 한다. 다시 말하자면, 임의의 시간집합 \\(t_1,t_2,\\cdots,t_m\\)에 대한 결합확률분포 \\(F(t_1,t_2,\\cdots,t_m)\\)이 이를 읨의로 \\(n\\)-시점 이동한 \\(t_1+n,t_2+n,\\cdots,t_m+n\\)에 대한 결합확률분포 \\(F(t_1+n,t_2+n,\\cdots,t_m+n)\\)와 같은 경우이다. 즉, \\[ F(t_1,t_2,\\cdots,t_m) = F(t_1+n,t_2+n,\\cdots,t_m+n) \\] \\(m=1\\)일 경우 평균과 분산이 모두 상수임을 의미하며 \\(m=2\\)일 경우 공분산이 다치 시차 \\(k\\)의 함수일 뿐 시간 \\(t\\)에는 종속하지 않아야 한다. \\[ Cov(x_t, x_{t+k}) = Cov(x_T, x_{T+k}) \\] 강안정적과정은 유한한 평균과 분산을 가질 필요가 없으므로 약안정성이 강안정성보다 더 엄격한 개념이 된다. 자기상관함수의 신뢰구간을 구하는 부분은 생략 2.3.2.5 예제) 안정적 시계열, 표본자기상관함수 및 유의성 검정 코스피 데이터를 바탕으로 분석을 진행하겠습니다. 데이터는 야후 파이넨스 라이브러리를 활용합니다. kospi = yf.download(&quot;^KS11&quot;,start=&quot;2000-01-04&quot;, end=&quot;2021-12-31&quot;) ## [*********************100%***********************] 1 of 1 completed kospi[&quot;rtn&quot;]=kospi[&quot;Adj Close&quot;].pct_change() #수익률 추가 data = kospi[&quot;rtn&quot;][1:] # 첫번째 열의 수익률은 nan이므로 제거 필요함. print(kospi.columns) ## Index([&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Adj Close&#39;, &#39;Volume&#39;, &#39;rtn&#39;], dtype=&#39;object&#39;) kospi ## Open High ... Volume rtn ## Date ... ## 2000-01-04 1028.329956 1066.180054 ... 195900 NaN ## 2000-01-05 1006.869995 1026.520020 ... 257700 -0.068675 ## 2000-01-06 1013.950012 1014.900024 ... 203500 -0.025874 ## 2000-01-07 949.169983 970.159973 ... 215700 -0.012635 ## 2000-01-10 979.669983 994.940002 ... 240200 0.040679 ## ... ... ... ... ... ... ## 2021-12-24 3009.479980 3025.770020 ... 537500 0.004756 ## 2021-12-27 3013.939941 3017.310059 ... 475000 -0.004276 ## 2021-12-28 3006.770020 3020.290039 ... 607000 0.006898 ## 2021-12-29 3002.899902 3007.719971 ... 545800 -0.008923 ## 2021-12-30 2999.750000 3005.360107 ... 460600 -0.005225 ## ## [5428 rows x 7 columns] # 코스피 종가 그래프 plt.cla() kospi[&quot;Adj Close&quot;].plot.line() plt.show() # 코스피 일간 수익률 그래프 plt.cla() kospi[&quot;rtn&quot;].plot.line() plt.show() 2.3.2.5.1 ACF 연산 nan을 제거하기 위해 첫번째 data를 제거하여야 합니다. import statsmodels.api as sm from statsmodels.tsa.stattools import acf acf(data, nlags=5) ## array([ 1. , 0.01690129, -0.01668116, 0.00358841, -0.01769711, ## -0.02776514]) 그래프 from statsmodels.graphics.tsaplots import plot_acf plot_acf(data, lags=10, use_vlines=True, zero = False, auto_ylims=True) # zero : 0차시 제거 # auto_ylims : 자동으로 y축 축적 제공됨. plt.show() 2.3.2.5.2 PACF 연산 import statsmodels.api as sm from statsmodels.tsa.stattools import pacf pacf(data, nlags=5) ## array([ 1. , 0.0169044 , -0.01697792, 0.00416667, -0.01813781, ## -0.0270649 ]) 그래프 from statsmodels.graphics.tsaplots import plot_pacf plot_pacf(data, lags=10, use_vlines=True, zero = False, auto_ylims=True) # zero : 0차시 제거 # auto_ylims : 자동으로 y축 축적 제공됨. plt.show() 2.3.2.5.3 Box test 여러 개의 자기상관계수 값들을 동시에 0인가 하는 귀무가설을 검정하기 위해서는 Q-통계량을 사용한다. Box-Pierce(1970) Q-통계량은 표본상관계수 제곱의 합을 이용하며 이 통계량을 소표본에서도 유용하도록 교정한 Liung-Box(1978)의 수정 Q-통계량은 다음과 같다. \\[ Q = T(T+2)\\Sigma^q_{j=1}\\hat{\\rho^2_j}/(T-j) \\sim \\chi^2(q) \\] 검정통계량의 분포는 귀무가설하에서 유도한다. Ljung-Box Q-통계량의 귀무가설은 “\\(q\\)개의 \\(\\hat{\\rho_j}\\)이 동시에 0이다.” 이므로 표본으로부터 구한 Q-통계량이 자유도 q를 갖는 \\(\\chi^2\\)-분포의 이론적 임계값보다 크다면 이들 중 최소한 하나의 값이 주어진 유의수준하에서 통계적으로 0과 다르다는 것으로 해석한다. \\(H_0\\) : The data are independently distributed \\(H_1\\) : The data are not independently distributed; they exhibit serial correlation. Liung-Box(1978) sm.stats.diagnostic.acorr_ljungbox(data, lags=[10]) ## lb_stat lb_pvalue ## 10 11.708956 0.305007 sm.stats.diagnostic.acorr_ljungbox(data, lags=10) ## lb_stat lb_pvalue ## 1 1.551099 0.212973 ## 2 3.062335 0.216283 ## 3 3.132281 0.371676 ## 4 4.833831 0.304776 ## 5 9.022923 0.108153 ## 6 9.023727 0.172248 ## 7 11.455119 0.119962 ## 8 11.617499 0.169103 ## 9 11.638545 0.234462 ## 10 11.708956 0.305007 Box-Pierce(1970) sm.stats.diagnostic.acorr_ljungbox(data, lags=[10], boxpierce=True) ## lb_stat lb_pvalue bp_stat bp_pvalue ## 10 11.708956 0.305007 11.69511 0.30598 2.3.3 편자기상관 편자기상관(partial autocorrelation)을 설명하기 위해 다음과 같은 AR(1)과정을 생각해 보자 \\[ x_t = \\phi_1x_{t-1}+\\alpha_t,\\quad \\alpha_t \\sim NID(0,\\sigma^2) \\] 이 식은 언뜻 보기에는 1시점 떨어진 두 관측치 \\(x_t\\)와 \\(x_{t-1}\\)만의 관계를 나타내는 것처럼 보이지만 후에 보는 것처럼 \\(x_t\\)와 \\(x_{t-2}\\)사이에도 일정한 상관관계를 갖게 된다. 따라서 예를 들어 AR(1) 과정을 따르는 \\(x_t\\)의 \\(\\rho_3 = corr(x_t,x_{t-3})\\)을 구해보면 영이 아닌 값을 가질 수 있다. 문제에 답하기 위하여 일반적으로 두 관측치 \\(x_t\\)와 \\(x_{t+k}\\) 사이의 직접적인 상관관계를 이야기 하는 외에도 \\(x_{t+1},x_{t+2},\\cdots,\\) 그리고 \\(x_{t+k-1}\\)의 상관관계를 계산해 볼 필요가 있게 된다. 즉, 다음과 같은 조건부 상관관계를 생각할 수 있다. \\[ Corr(x_t,x_{t+k}|x_{t+1},\\cdots,x_{t+k-1}) \\] 이를 ‘편자기상관’(partial autocorrelation; PAC)이라고 한다. \\(x_t\\)와 \\(x_{t+k}\\) 사이의 편자기상관계수는 \\((x_t-\\hat{x}_t)\\)와 \\((x_{t+k}-\\hat{x}_{t+k})\\)사이의 일반자기상관계수로 정의한다. 즉, \\(x_t\\)와 \\(x_{t+k}\\) 사이의 편자기상관계수를 \\(\\phi_{kk}\\)라고 표시할때 이는 다음과 같이 정의된다. \\[ \\phi_{kk} = \\frac{Cov[(x_t-\\hat{x}_t),(x_{t+k}-\\hat{x}_{t+k})]}{\\sqrt{Var(x_t-\\hat{x}_t)}\\sqrt{Var(x_{t+k}-\\hat{x}_{t+k})}} \\] 실제로 위의 식을 이해하거나 이 공식으로 편자기상관게수를 구하는 것은 쉽지 않을 것이다. 보다 직관적인 설명은 \\(\\phi_{kk}\\)는 다음과 같은 회귀식 (AR(\\(k\\))모형)에서 \\(k\\)-번째 회귀계수와 같은 것으로 알려져 있다. \\[ x_{t+k}=\\phi_{k1}x_{t+k-1}+\\phi_{k2}x_{t+k-2}+\\cdots+\\phi_{kk}x_{t}+a_{t+k} \\] 단 \\(\\phi_{ki}\\)는 AR(\\(k\\))모형의 \\(i\\)-번째 회귀계수를 나타낸다. \\(a_{t+k}\\)는 정규분포하는 오차항으로 \\(j\\ge1\\)에 대하여 \\(x_{t+k-j}\\)와 비상관이다. 추정하는 방법으로, ‘율-워커(Yule-Walker) 방정식’을 사용할 수 있다. AR(\\(k\\))모형 식에서 양변에 \\(x_{t+k-j}\\)를 곱하고 기대값을 취하면 다음 식을 얻는다 \\[ \\gamma_j=\\phi_{k1}\\gamma_{j-1}+\\phi_{k2}\\gamma_{j-2}+\\cdots+\\phi_{kk}\\gamma_{j-k} \\] 양변을 다시 \\(x_i\\)과정의 분산 \\(\\gamma_0\\)로 나누면 \\[ \\rho_j=\\phi_{k1}\\rho_{j-1}+\\phi_{k2}\\rho_{j-2}+\\cdots+\\phi_{kk}\\rho_{j-k} \\] 와 같은 방적식 체계를 얻을 수 있으며 이를 율 워커 방정식이라고 부른다. 이를 크레이머 공식을 통해 \\(\\phi_{kk}\\)를 구할 수 있다. 표본편자기상관함수 \\(\\hat{\\phi}_{kk}\\)는 \\(\\rho_j\\) 대신 \\(\\hat{\\rho_j}\\)를 사용하여 계산한다. \\(\\rho_j\\) 대신 \\(\\hat{\\rho_j}\\)를 사용하는 경우에도 율 -워커 방정식으로부터 구한 \\(\\hat{\\phi}\\)들은 최우추정량과 동일한 점근분포를 갖는 것으로 알려져 있다. 확률과정이 AR(\\(p\\))를 따를 때 \\(\\hat{\\phi}_{kk}\\)의 표준편차는 귀무가설에 관계업이 다음과 같이 근사할 수 있다.(Quenouille(1949)) \\[ SE(\\hat{\\phi}_{kk}) \\simeq 1/\\sqrt{T} \\] 그러므로 \\(\\hat{\\phi}_{kk}\\pm 2/\\sqrt{T}\\)는 \\(\\hat{\\phi}_{kk}\\)의 2표준편차 신뢰구간이 된다. 2.3.3.1 예제) 표본편자기상관함수(자기상관함수와 편자기상관함수) 2.3.3.1.1 ACF 연산 nan을 제거하기 위해 첫번째 data를 제거하여야 합니다. import statsmodels.api as sm from statsmodels.tsa.stattools import acf acf(data, nlags=5) ## array([ 1. , 0.01690129, -0.01668116, 0.00358841, -0.01769711, ## -0.02776514]) 그래프 from statsmodels.graphics.tsaplots import plot_acf plot_acf(data, lags=10, use_vlines=True, zero = False, auto_ylims=True) # zero : 0차시 제거 # auto_ylims : 자동으로 y축 축적 제공됨. plt.show() 2.3.3.1.2 PACF 연산 import statsmodels.api as sm from statsmodels.tsa.stattools import pacf pacf(data, nlags=5) ## array([ 1. , 0.0169044 , -0.01697792, 0.00416667, -0.01813781, ## -0.0270649 ]) 그래프 from statsmodels.graphics.tsaplots import plot_pacf plot_pacf(data, lags=10, use_vlines=True, zero = False, auto_ylims=True) # zero : 0차시 제거 # auto_ylims : 자동으로 y축 축적 제공됨. plt.show() 2.3.4 월드분해정리와 선형필터 2.3.4.1 백색잡음과정(white-noise process) \\(a_t\\)를 다음과 같은 평균과 (공)분산을 갖는 분포로부터의 일련의 비상관 확률변수라고 하자. \\[ E(a_t)=0 \\\\ Var(a_t)=\\sigma^2_a \\\\ Cov(a_t,a_{t-k})=0, \\qquad \\forall k \\neq0 \\] 이러한 일련의 과정은 현시점까지의 자료가 미래에 대한 예측정보를 전혀 포함하고 있지 않다는 의미에서 백색잡음과정(white-noise process)라고 부른다. 2.3.4.2 월드분해정리 (Wold’s decomposition theorem) 모든 약안정적이고 비결정적인 ‘확률과정’\\(x_t-\\mu\\)는 일련의 무상관 확률변수의 선형결합으로 표현할 수 있다. 이 때의 선형결합을 ‘선형필터’(linear filter)라고 하며 비결정적인 부분을 나타내는 비조건부 평균 \\(\\mu\\)를 생략하는 경우 (즉, 0이라는 상수값을 가정한 것과 동일) 월드분해정리의 함의는 일반적인 선형확률과정 \\(x_t\\)를 ‘선형필터표현식’(linear filter representaion)으로 나타낼 수 있다는 것이다. 2.4 자기회귀모형 일반적인 ’p-차 자기회귀모형’은 다음과 같이 쓸 수 있으며 기호로 AR(p)라고 표시한다. \\[ x_t=\\phi_1x_{t-1}+\\phi_2x_{t-2}+\\cdots+\\phi_px_{t-p}+a_t\\\\ 또는\\\\ (1-\\phi_1L-\\phi_2L^2-\\cdots-\\phi_pL^p)=a_t\\\\ \\phi(L)x_t=a_t \\] 확률과정 x_t가 안정적이기 위해서는 래그다항식 \\(\\phi(L)\\)의 행렬식(determinant)을 0으로 두었을 때 이의 모든 근(또는 해)이 ‘복소수 단위원’의 ’밖에’ 존재하여야 한다. 즉, \\[ 1-\\phi_1z-\\phi_2z^2-\\cdots-\\phi_pz^p=0 \\] 에서 z의 모든 근(차수 p개만큼 존재할 것으로 기대)이 복소수 단위원(complex unit circle)의 밖에(outside) 존재하여야 한다. 안정성 조건을 달리 표현하는 방법도 있다. AR(\\(p\\))모형을 따르는 시계열 \\(x_t\\)의 자기상관함수는 후술하는 것 처럼 \\(p\\)-차 차분방정식의 형태를 가지므로 이의 특성방정식(characteristic equation)의 일반해는 다음과 같다. \\[ \\rho_k = c_1\\lambda_1^k + c_2\\lambda_2^k + \\cdots + c_p\\lambda_p^k \\quad for \\quad k\\ge0 \\] 단, \\(\\lambda_i\\)는 \\(z^p-\\phi_1z^{p-1}-\\cdots-\\phi_p=0\\) 방정식의 해이다. 이 경우 차분 방정식이론에 따르면 \\(x_t\\)의 안정성 조건은 \\(\\lambda\\)가 모두 복소수 단위원의 안(inside)에 존재하는 것이다. 2.4.1 예시 (안정성 조건 확인) AR(2)모형으로 설정하고 추정하였다고 하자. import statsmodels.api as sm from statsmodels.tsa.ar_model import AutoReg res = AutoReg(data, lags = 2).fit() #print(res.summary()) #print(res.diagnostic_summary()) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) print(&quot;AR Roots : &quot;, res.roots) ## AR Roots : [0.46357281-7.66742076j 0.46357281+7.66742076j] print(&quot;Inverted AR roots : &quot;, res.roots**(-1)) ## Inverted AR roots : [0.0078566+0.12994694j 0.0078566-0.12994694j] 다음은 AR[0,0,0,0,5]를 추정한 결과이다. import statsmodels.api as sm from statsmodels.tsa.ar_model import AutoReg res2 = AutoReg(data, lags = [5]).fit() #print(res2.summary()) #print(res2.diagnostic_summary()) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) print(&quot;AR Roots : &quot;, res2.roots) ## AR Roots : [-2.04778776-0.j -0.63280122-1.94756189j -0.63280122+1.94756189j ## 1.6566951 -1.20365944j 1.6566951 +1.20365944j] print(&quot;Inverted AR roots : &quot;, res2.roots**(-1)) ## Inverted AR roots : [-0.48833186+0.j -0.15090284+0.4644312j -0.15090284-0.4644312j ## 0.39506877+0.28703426j 0.39506877-0.28703426j] 2.4.2 AR(1) 모형 자기회귀모형의 특성을 이의 가장 간단한 형태인 AR(1) 모형을 사용하여 살펴보자. \\[ x_t = \\phi x_{t-1} + a_t \\\\ 또는\\\\ (1-\\phi L)x_t = \\phi(L)x_t = a_t \\] \\(x_t\\)가 안정적 과정인 경우 식을 다음과 같이 변형할 수 있을 것이다. \\[ x_t = (1-\\phi L)^{-1}a_t\\\\ =(1+\\phi L + \\phi ^2L^2+\\cdots)a_t\\\\ =a_t + \\phi a_{t-1}+ \\phi ^2 a_{t-2}+ \\phi^3 a_{t-3} + \\cdots \\] 안정적 과정에서 \\(E(x^2_t)=E(x^2_{t-k})=\\sigma^2_x=\\gamma_0\\)가 성립하므로 \\[ E(x_t)=0 \\quad \\forall t\\\\ Var(x_t)=E[(x_t-E(x_t))^2]=\\sigma^2+\\phi^2 \\sigma^2 + \\phi^4 \\sigma^2 + \\cdots\\\\ =\\frac{1}{1-\\phi^2}\\sigma^2 \\] 식은 \\(x_t\\)의 비조건부평균, 즉 장기평균값이 영임을 보여주고 있다. 만일 AR(1)과정을 보다 일반적으로 \\[ x_t - \\mu = \\phi(x_{t-1}-\\mu)+a_t \\] 와 같이 평균으로부터의 이탈부분이 자기회귀하는 것으로 설정하였다면, \\(E(x_t) = 1/(1-\\phi L) = 1/(1-\\phi)\\)가 된다. 두 번째 등호가 성립하는 이유는 상수에 래그를 취해도 상수이기 때문이다. (즉, \\(cL=L\\)) \\(Var(x_t)=\\sigma^2/(1-\\phi^2)\\)에서 AR(1)과정의 비조건부분산, 즉 장기분산값을 나타내는데 \\(|\\phi|&lt;1\\)로 인한 확률과정 \\(x_t\\)의 분산 \\(Var(x_t)\\)는 백색잡음의 분산 \\(\\sigma^2\\)보다 큼을 알 수 있다. 잔차항의 변동폭이 실제값의 변동폭보다 작은 것이 바로 이 이유에서 비롯함을 알 수 있다. AR(1)과정의 공분산(covariance)의 특성을 살펴보자. \\[ \\gamma_k = E[(x_t-E(x_t))(x_{t-k}-E(x_{t-k}))]\\\\ =E[(\\phi^k x_{t-k}+\\Sigma^{k-1}_{j=0}\\phi^j a_{t-j})x_{t-k}]\\\\ =\\phi^k \\gamma_0 \\quad (\\because x_{t-k}=\\Sigma^{\\infty}_{j=0}\\phi^j a_{t-k-j})\\\\ =\\phi(\\phi^{k-1}\\gamma_0)=\\phi \\gamma_{k-1} \\] 그러므로 AR(1)모형은 공분산과정 방적식과 자료생성모형이 서로 같다는 특성이 있다.그리고 \\(|\\phi|&lt;1\\)가 만족하면 ‘안정성조건’을 만족한다고 한다. 2.4.2.1 AR(1)모형의 안정성 조건 앞에서 설명한 안정성 조건을 AR(1)모형에 적용하여 보면 \\(\\phi(L)=1-\\phi L\\)이므로 안정성을 위해서는 \\(|\\phi(L)|=0\\)의 근이 단위원 밖에 존재하여야 한다. 즉, \\[ |1-\\phi z| = 0 \\quad or \\quad |z|=1/|\\phi| \\] 그러므로 안정성 조건 \\(|z|&gt;1\\)은 \\(|\\phi|&lt;1\\)을 의미한다. 만일 근이 경계선상인 1이면 안정성 조건을 만족하지 않으며 이는 “확률보행과정”(random walk process)라고 할 수 있을 것이다. 이 경우 분산이 발산한다. 2.4.2.2 AR(1)모형의 자기상관함수(ACF) AR(1)모형의 자기상관함수는 다음과 같이 계산한다. \\[ \\rho_k = \\gamma_k/\\gamma_0 = \\phi^k \\] 그러므로 안정성 조건을 만족하면서 \\(phi&gt;0\\)이면 ACF는 \\(k\\)가 증가함에 따라 지수적으로 0에 가까워지고 만일 \\(\\phi&lt;0\\)이면 ACF는 진동하는(oscillatory)형태로 0에 접근한다. 두 경우 모두 \\(\\phi\\)가 비정상과정이 되는 한계값 \\(\\pm1\\)에 가까운 경우 감소하는 속도는 매우 느리게 된다. 표본 ACF \\(\\hat{\\rho}_k\\)의 표준편차는 다음과 같다. \\[ SD(\\hat{\\rho}_k) \\simeq \\sqrt{(\\frac{1}{T})(1+2\\hat{\\rho}^2_1+\\cdots+2\\hat{\\rho}^2_{k-1})} \\] 2.4.2.3 AR(1) 모형의 편자기상관함수(Partial ACF) AR(1) 모형의 PACF는 다음과 같다. \\[ \\phi_{kk} = \\begin {cases} \\rho_1 = \\phi_1, \\quad k=1 \\\\ 0, \\quad k \\ge 2 \\end {cases} \\] 그러므로 AR(1)과정의 PACF는\\(\\phi_1\\)의 부호에 따라 첫 번째 래그에서 양 또는 음의 스파이크를 보이고 그 후의 래그에서는 없어진다. 표본 PACF \\(\\hat{\\phi}_{kk}\\)의 SD는 \\(1/\\sqrt T\\)이다. 2.4.2.4 예제) AR(1)과정 : 시뮬레이션 다음은 두 개의 AR(1)과정의 시뮬레이션이다. AR1_95와 AR1_30은 각각 \\(\\phi = 0.95, \\phi = 0.3\\)을 가정한 것이고 두 계열 모두 비조건부평균을 0으로 가정하였다. from statsmodels.tsa.arima_process import ArmaProcess plt.cla() fig, ax = plt.subplots(3,2, constrained_layout=True) # ar1_95 phi = 0.95 plt.subplot(3, 2, 1) ar1_95_ar_parm = np.array([1, -0.95]) # 0.95를 넣기 위해서는 음수로 넣어야 하며, 1은 lag 0에서를 의미함. ar1_95_ma_parm = np.array([1]) AR1_95 = ArmaProcess(ar1_95_ar_parm, ar1_95_ma_parm).generate_sample(nsample=300) plt.plot(AR1_95) plt.title(&#39;AR(1)=0.95&#39;) # ar1_30 phi = 0.3 plt.subplot(3, 2, 2) ar1_30_ar_parm = np.array([1, -0.3]) ar1_30_ma_parm = np.array([1]) AR1_30 = ArmaProcess(ar1_30_ar_parm, ar1_30_ma_parm).generate_sample(nsample=300) plt.plot(AR1_30) plt.title(&#39;AR(1)=0.30&#39;) #ar1_95 acf plot_acf(AR1_95, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,0], title =&#39;AR1_95 ACF&#39;) #ar1_30 acf plot_acf(AR1_30, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,1], title =&#39;AR1_30 ACF&#39;) #ar1_95 pacf plot_pacf(AR1_95, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,0], title =&#39;AR1_95 PACF&#39;) #ar1_30 pacf plot_pacf(AR1_30, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,1],title =&#39;AR1_30 PACF&#39; ) plt.show() 두 계열의 표본 ACF를 보면, AR(1)과정임에도 불구하고 두 계열 모두 래그 2 이상에서도 자기상관을 가지고 있음을 확인할 수 있다(?). 어떤 임의의 자료가 있을 때 이의 Sample ACF, Sample PACF가 위의 그림과 유사하다고 하자. 즉, 표본 ACF값이 상대적으로 부드럽게 감소하고(‘taper-off’), 표본 PACF 값은 래그 1 이후에도 0으로 갑자기 줄어드는 경우(‘cut-off after lag 1’)이다. 이 경우 우리는 임의의 자료가 AR(1)과정에서 생성된 것이라고 추측할 수 있으며, 이 자료를 AR(1)모형으로 표현하여 모형을 추정하게 되는 것이다. 2.4.3 AR(2) 모형 AR(2)모형은 다음과 같다. \\[ x_t-\\mu = \\phi_1(x_{t-1} - \\mu) + \\phi_2(x_{t-2}-\\mu)+a_t \\] 또는 래그연산자 \\(L\\)을 사용하여 다음과 같이도 쓸 수 있다. 단, 이후 식들에서는 편의를 위해 \\(\\mu=0\\)을 가정한다. \\[ (1-\\phi_1L-\\phi_2L^2)(x_t-\\mu)=\\phi(L)x_t = a_t \\] AR(1)과정과 동일한 방법으로 안정성 조건을 확인한다면, 다음과 같다. \\[ \\phi_1 + \\phi_2 &lt; 1\\\\ -\\phi_1+ \\phi_2 &lt; 1\\\\ -1&lt;\\phi_2&lt;1 \\] AR(2)모형의 자기공분산을 계산하여보자. \\[ E(x_t,x_{t-k}) = \\phi_1E(x_{t-1}x_{t-k})+\\phi_1E(x_{t-2}x_{t-k})+E(a_tx_{t-k})\\\\ \\gamma_k-\\phi_1\\gamma_{k-1}-\\phi_2\\gamma_{k-2}=E(a_tx_{t-k})\\\\ \\quad \\\\ \\gamma_0-\\phi_1\\gamma_1-\\phi_2\\gamma_2 = E(a_tx_{t-k}) = \\sigma^2_a\\\\ \\gamma_k-\\phi_1\\gamma_{k-1}-\\phi_2\\gamma_{k-2} = E(a_tx_{t-k}) = 0, \\quad k = 1,2,\\cdots \\] 따라서 AR(1)모형의 경우와 유사하게 AR(2)과정의 자기공분산 방정식 또한 자료생성과정과 같은 형태를 가짐을 알 수 있다. 2.4.3.1 AR(2)모형의 자기상관함수(ACF) 자기상관계수 방정식 또한 자기공분산 방정식과 같이 AR(2)자료 생성 과정과 같다. \\[ \\gamma_k-\\phi_1\\gamma_{k-1}-\\phi_2\\gamma_{k-2} = 0 \\\\ (\\gamma_k-\\phi_1\\gamma_{k-1}-\\phi_2\\gamma_{k-2})/\\gamma_0 = 0/\\gamma_0 \\\\ \\rho_k-\\phi_1\\rho_{k-1}-\\phi_2\\rho_{k-2} = 0, \\quad k=1,2,\\cdots \\\\ \\quad\\\\ \\quad\\\\ \\rho_1=\\phi_1/(1-\\phi_2) \\\\ \\rho_2=\\frac{\\phi^2_1}{(1-\\phi_2)}+\\phi_2=\\frac{\\phi^2_1+\\phi_2-\\phi^2_2}{1-\\phi_2}\\\\ (\\because \\rho*k=*\\rho{-k}) \\] 이때 \\(\\gamma_0(1-\\phi_1\\rho_1-\\phi_2\\rho_2)=\\sigma^2_2\\)이므로 위에서 구한 \\(\\rho_1\\)와 \\(\\rho_2\\)를 대입하면 AR(2)과정을 따르는 \\(x_t\\)의 분산\\(\\sigma^2_x=\\gamma_0\\)는 다음과 같다. \\[ \\gamma_0 = \\sigma^2_x = (\\frac{1-\\phi_2}{1+\\phi_2}) \\cdot (\\frac{\\sigma^2_a}{(\\phi_1+\\phi_2-1)(\\phi_2-\\phi_1-1)}) \\] 2.4.3.2 AR(2)모형의 편자기상환상관함수(Partial ACF) AR(2)과정의 PACF는 다음과 같다. \\[ \\phi_{11}=\\rho_1=\\frac{\\phi_1}{1-\\phi_2} \\\\ \\phi_{22}=\\frac{\\rho_2-\\rho^2_1}{1-\\rho^2_1}=\\phi_2 \\\\ \\phi_{33}=0, \\quad for \\ k\\ge 3 \\] 2.4.3.3 예제) AR(2)과정 : 시뮬레이션 다음 과정은 \\((\\phi_1,\\phi_2) = (1.2,-0.5)\\)와 \\((\\phi_1,\\phi_2) = (0.4,0.2)\\)의 모수를 갖는 AR(2)과정을 시뮬레이션하고 이들의 표본 ACF, PACF를 계산하는 코드이다. from statsmodels.tsa.arima_process import ArmaProcess plt.cla() fig, ax = plt.subplots(3,2,constrained_layout=True) # ar2_1 phi = 1.2,-0.5 plt.subplot(3, 2, 1) ar2_1_ar_parm = np.array([1, -1.2, 0.5]) # 0.95를 넣기 위해서는 음수로 넣어야 하며, 1은 lag 0에서를 의미함. ar2_1_ma_parm = np.array([1]) AR2_1 = ArmaProcess(ar2_1_ar_parm, ar2_1_ma_parm).generate_sample(nsample=300) plt.plot(AR2_1) plt.title(&#39;AR(1)=1.2, AR(2)=-0.5&#39;) # ar2_2 phi = 0.4, 0.2 plt.subplot(3, 2, 2) ar2_2_ar_parm = np.array([1, -0.4, -0.2]) ar2_2_ma_parm = np.array([1]) AR2_2 = ArmaProcess(ar2_2_ar_parm, ar2_2_ma_parm).generate_sample(nsample=300) plt.plot(AR2_2 ) plt.title(&#39;AR(1)=0.4, AR(2)=0.2&#39;) #ar2_95 acf plot_acf(AR2_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,0], title =&#39;AR(2)_1 ACF&#39;) #ar2_30 acf plot_acf(AR2_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,1], title =&#39;AR(2)_2 ACF&#39;) #ar2_95 pacf plot_pacf(AR2_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,0], title =&#39;AR(2)_1 PACF&#39;) #ar2_30 pacf plot_pacf(AR2_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,1],title =&#39;AR(2)_1 PACF&#39; ) plt.show() 두 시뮬레이션 모두 표본 PACF를 보면 래그 2 이후 모두 단절(cutt-off)되는 특성을 보이고 있다. 역으로 표본 PACF로 부터 AR(2)모형이 이 데이터들의 자료 생성 과정으로 적절한 후보임을 알 수도 있을 것이다. 또한 표본 ACF를 보면 점차 감소(taper-off)하는 모형을 가지는데 긴 래그에서 집단적으로 작지만 음의 계수를 띄고 있는 것을 확인할 수 있다. 이러한 AR(2)과정의 움직임을 ‘준사이클’(pseudo-cycle)이라고 부르기도 한다. 2.4.4 p-차 자기회귀모형(AR(p) 모형) \\(p\\)-차 자기회귀 모형의 표현식은 다음과 같다. \\[ x_t = \\phi_1x_{t-1}+\\phi_2x_{t-2}+\\cdots+\\phi_px_{t-p}+a_t \\] AR(p) 모형에서 공분산을 계산하면 다음과 같다. \\[ \\gamma_k=E(x_tx_{t-k})\\\\ =\\phi_1E(x_{t-1}x_{t-k})+\\phi_2E(x_{t-2}x_{t-k})+\\cdots+\\phi_pE(x_{t-p}x_{t-k})+E(a_tx_{t-k}) \\\\ =\\phi_1\\gamma_{k-1}+\\phi_2\\gamma_{k-2}+\\cdots+\\phi_p\\gamma_{k-p} \\qquad for \\ k&gt;0 \\\\ \\gamma_0 = \\Sigma^p_{j=1}\\phi_j\\gamma_j+\\sigma^2_a, \\qquad for \\ k=0 \\quad (\\because \\quad \\gamma_k=\\gamma_{-k}) \\] 2.4.4.1 AR(p)모형의 자기상관함수(ACF) ACF는 지수적으로 감소하는 항 또는 sin곡선들이 서로 혼합된 형태로 차차 감솨하는 모양의 띄게 된다. 일부 근이 복소수인 경우 자기상관함수는 점차 감소하는 sin 곡선 모양을 한다. 2.4.4.2 AR(p)모형의 편자기상관함수(PACF) AR(p)모형의 PACF \\(\\phi_{kk}\\)는 래그 \\(p\\)이후에는 사라지게 된다. 즉 AR(p)모형의 경우 ACF는 점차적으로 감소하는 반면, PACF는 래그 \\(p\\) 이후에 0이 되는 특성이 있다. 2.4.4.3 AR(p) 모형의 MA(\\(\\infty\\)) 모형으로의 전환 다음과 같은 안정적 \\(p\\)-차 자기회귀 모형을 생각해보자. \\[ (1-\\phi_1L-\\phi_1L-\\cdots-\\phi_1L)x_t = a_t \\\\ \\phi(L)x_t = a_t \\] 이를 다음과 같이 다시 쓸 수 있다. \\[ x_t = a_t/\\phi(L) = \\psi(L)a_t \\] 단, \\(\\psi(L) = (1+\\psi_1L+\\psi_2L^2+\\cdots)\\)로 우리고 구하고자 하는 래그 다항식으며 다음을 만족하게 된다. \\[ \\phi(L)\\psi(L)=1 \\] 2.4.4.3.1 충격반응함수(impulse response function) 계수 \\(\\psi_k\\)는 \\(t\\)-시점의 충격 \\(a_t\\)가 \\((t+k)\\)-기의 \\(x_t\\)에 미치는 영향을 측정한다. 즉, 안정적 확률과정의 경우 \\(\\partial x_{t-k}/\\partial a_t = \\psi_k\\)가 성립한다. 이를 ‘충격반응함수’(impulse response function)라고 하며 AR(p)모형의 계수 자체로는 이것을 계산할 수 없고 이를 MA(\\(\\infty\\))모형으로 전환하고 이때의 가중치 \\(\\psi\\)를 계산해야 할 필요가 있다. 2.4.4.3.1.1 diy 예제) 충격반응함수 statsmodels에서는 AR에 대해서는 충격반응함수를 제공하고 있지 않습니다. ARIMA 함수를 가져와서 사용하겠습니다. 다음은 AR(2)모형의 예제입니다. import statsmodels.api as sm res = sm.tsa.arima.ARIMA(AR2_2, order=(2, 0, 0)).fit() #p=2 d = 0 q = 0 임으로 AR(2) #print(res.summary()) print(res.impulse_responses(steps=10)) ## [1. 0.36771596 0.32748926 0.19112533 0.13324758 0.08574574 ## 0.05715015 0.03750172 0.02477848 0.01632206 0.01076614] 2.5 이동평균 모형 일반적인 q-차 이동평균모형(MA(q)모형)의 표현식은 다음과 같다. \\[ x_t = a_t - \\theta_1a_{t-1} - \\theta_2a_{t-2} - \\cdots - - \\theta_qa_{t-q} + \\mu \\\\ = (1 - \\theta_1B- \\theta_2B^2 - \\cdots - \\theta_qB^q )a_t + \\mu\\\\ = \\theta(B)a_t+ \\mu \\] AR(p)모형에서는 안정성 조건을 이야기하였다. 그러나 유한한 차수 MA(q)모형에서는 기대값이 항상 0\\(E(x_t)=0\\)이고, 분산이 \\(\\sigma^2_x=(1+\\theta^2_1+\\theta^2_2+\\cdots+\\theta^2_q)\\sigma^2_a &lt; \\infty\\) 이므로 항상 안정적이므로 안정성 조건을 별도로 확인할 필요는 없다. 2.5.1 가역성 조건 \\(\\theta(L)\\)에 대해서 \\[ |\\theta(L)| = |1-\\theta_1L-\\theta_2L^2-\\cdots_-\\theta_qL^q|=0 \\] 의 모든 근들이 모두 복소수 단위원의 ‘밖에’(outside)에 존재하는 경우 \\(x_t\\)는 ‘가역적 과정’(invertible process)라고 한다. 이동평균모형은 현시점에서 어떤 이벤트(충격)이 주어졌을 때 효과가 단기간에만 지속되는 경우를 모형화하는 데 유용하다. 2.5.2 MA(1) 모형 MA(1)모형은 다음과 같다. (\\(\\mu\\) 생략) \\[ x_t = a_t - \\theta a_{t_1} \\\\ =(1-\\theta L)a_t \\\\ =\\theta(L)a_t \\] MA(1)을 따르는 확률과정의 분산과 공분산은 다음과 같다. \\[ \\gamma_0 = \\sigma^2_a(1+\\theta^2) \\\\ \\gamma_1 = -\\sigma^2_a \\theta \\\\ \\gamma_k = 0, \\ for \\ k&gt;1 \\] 2.5.2.1 MA(1)모형의 가역성 조건 MA과정이 수렴하는 AR 표현식을 가지려면, \\[ (1-\\theta L)^{-1}x_t = a_t \\\\ (1+\\theta L + \\theta^2 L^2 +\\cdots)x_t = a_t \\] 에서 \\(|\\theta|&lt;1\\)의 조건을 만족하여야 한다. 다시 말하자면 MA과정 양변에 \\(\\theta^{-1}(L)\\)를 곱하는 연산이 가능하다는 뜻 2.5.2.2 MA(1)모형의 자기상관함수(ACF) MA(1)과정의 ACF는 래그 1이후 소멸한다. 즉, \\[ \\rho_1 = \\frac{-\\theta}{1+\\theta^2} \\\\ \\rho_k = 0, \\quad for \\ k&gt;1 \\] 2.5.2.3 MA(1)모형의 편자기상관함수(PACF) MA(1)과정의 PACF는 다음과 같다. \\[ \\phi_{11} = \\rho_1 = \\frac{-\\theta}{1+\\theta^2} = \\frac{-\\theta(1-\\theta^2)}{1-\\theta^4} \\\\ \\phi_{22} = \\frac{-\\rho^2_1}{1-\\rho^2_1} = \\frac{-\\theta^2(1-\\theta^2)}{1-\\theta^6} \\\\ \\vdots \\\\ \\phi_{kk} = \\frac{-\\theta^k(1-\\theta^2)}{1-\\theta^{2(k+1)}}, \\quad for \\ k\\ge1\\\\ \\] 그러므로 래그 1 이후 소멸하는 ACF의 경우와는 달리 MA(1)과정의 PACF는 지수적으로 점차 감소하며 그 모양은 \\(\\theta\\)의 부호(\\(\\therefore \\quad \\rho_1\\)의 부호)에 따라 다르다. 2.5.2.4 예제) MA(1)과정의 실현값 : 시뮬레이션 다음 예제는 시뮬레이션한 MA(1)과정들로 MA1_1과 MA1_2는 각각 \\(\\theta = 0.5\\)와 \\(\\theta = - 0.3\\)을 가정하고 있다. from statsmodels.tsa.arima_process import ArmaProcess plt.cla() fig, ax = plt.subplots(3,2,constrained_layout=True) # MA1_1 theta = 0.5 plt.subplot(3, 2, 1) ma1_1_ar_parm = np.array([1]) ma1_1_ma_parm = np.array([1, -0.5]) MA1_1 = ArmaProcess(ma1_1_ar_parm, ma1_1_ma_parm).generate_sample(nsample=300) plt.plot(MA1_1) plt.title(&#39;MA(1)=0.5&#39;) # MA1_2 theta = -0.3 plt.subplot(3, 2, 2) ma1_2_ar_parm = np.array([1]) ma1_2_ma_parm = np.array([1, 0.3]) MA1_2 = ArmaProcess(ma1_2_ar_parm, ma1_2_ma_parm).generate_sample(nsample=300) plt.plot(MA1_2) plt.title(&#39;MA(1)=-0.3&#39;) # MA1_1 acf plot_acf(MA1_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,0], title =&#39;MA1_1 ACF&#39;) # MA1_2 acf plot_acf(MA1_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,1], title =&#39;MA1_2 ACF&#39;) # MA1_1 pacf plot_pacf(MA1_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,0], title =&#39;MA1_1 PACF&#39;) # MA1_2 pacf plot_pacf(MA1_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,1],title =&#39;MA1_2 PACF&#39; ) plt.show() 표본 ACF는 래그 1 이후 소멸함을 알 수 있다. 따라서 AR과정과 반대로 ACF의 cut-off 특성은 자료의 생성과정이 MA과정인지, 그리고 차수는 무엇인지에 대한 유용한 정보를 포함하고 있음을 알 수 있다. 2.5.3 MA(2) 모형 MA(2)모형 과정은 다음과 같이 쓸 수 있다.(\\(\\mu\\) 생략) \\[ x_t = a_t - \\theta_1 a_{t_1} - \\theta_2 a_{t_2}\\\\ =(1-\\theta L-\\theta_2 L^2)a_t \\\\ \\] 이 모형 또한 유한차수 이동평균모형이기 때문에 \\(x_t\\)는 항상 안정적 과정이다. 2.5.3.1 MA(2)모형의 가역성 조건 가역성 조건은 \\((1-\\theta L-\\theta_2 L^2)a_t=0\\)의 근이 복소수 단위원 밖에 존재하는 것이다. 그러므로 AR(2)의 경우와 유사하게 다음의 조건이 만족되는 경우 MA(2)모형은 가역성을 갖는다. \\[ \\theta_2 + \\theta_1&lt;1 \\\\ \\theta_2 - \\theta_1&lt;1 \\\\ -1&lt;\\theta_2&lt;1 \\] 2.5.3.2 MA(2)모형의 자기상관함수(ACF) MA(2)과정의 자기공분산은 다음과 같다. \\[ \\gamma_0 = (1+\\theta^2_1+\\theta^2_2)\\sigma^2_a \\\\ \\gamma_1 = -\\theta_1(1-\\theta_2)\\sigma^2_a \\\\ \\gamma_2 = -\\theta_2\\sigma^2_a \\\\ \\gamma_k = 0, \\ for \\ k&gt;2 \\] 즉, 자기공분산은 래그 2 이후에 소멸하는 것이다. 그러므로 MA(2)과정의 ACF는 다음과 같이 계산하며 래그 2 이후에 소멸하는 특성을 갖는다. \\[ \\rho_k = \\begin{cases} (-\\theta_1(1-\\theta_2))/(1+\\theta^2_1+\\theta^2_2), \\quad k = 1 \\\\ -\\theta_2/(1+\\theta^2_1+\\theta^2_2), \\quad k = 2\\\\ 0, \\quad k&gt;2 \\end{cases} \\] 2.5.3.3 MA(2)모형의 편자기상관함수(PACF) \\(k\\ge3\\)인 경우 \\(\\rho_k=0\\)임을 유지하면서 PACF는 다음과 같이 계산할 수 있다. \\[ \\phi_{11} = \\rho_1 \\\\ \\phi_{22} = \\frac{\\rho_2-\\rho^2_1}{1-\\rho^2_1}\\\\ \\phi_{33} = \\frac{\\rho^3_1-\\rho_1\\rho_2(2-\\rho_2)}{1-\\rho^2_2-2\\rho^2_1(1-\\rho_2)}\\\\ \\vdots \\] 그러므로 PACF는 \\(\\theta_1\\)과 \\(\\theta_2\\)의 크기 및 부호에 따라 지수적으로 점차 감소하거나 또는 점차 감소하는 sin파장을 그리게 된다. 2.5.3.4 예제) MA(2)과정의 실현값 다음 예제는 시뮬레이션한 MA(2)과정들로 MA2_1과 MA2_2는 각각 \\(\\theta_1 = 0.6,\\theta_2=0.2\\)와 \\(\\theta_1 = -0.4,\\theta_2=0.3\\)을 가정하고 있다. from statsmodels.tsa.arima_process import ArmaProcess plt.cla() fig, ax = plt.subplots(3,2,constrained_layout=True) # MA1_1 theta = 0.6, 0.2 plt.subplot(3, 2, 1) ma2_1_ar_parm = np.array([1]) ma2_1_ma_parm = np.array([1, -0.6, -0.2]) MA2_1 = ArmaProcess(ma2_1_ar_parm, ma2_1_ma_parm).generate_sample(nsample=300) plt.plot(MA2_1) plt.title(&#39;MA(1)=0.6, MA(2)=0.2&#39;) # MA1_2 theta = -0.4,0.3 plt.subplot(3, 2, 2) ma2_2_ar_parm = np.array([1]) ma2_2_ma_parm = np.array([1, 0.4,-0.3]) MA2_2 = ArmaProcess(ma2_2_ar_parm, ma2_2_ma_parm).generate_sample(nsample=300) plt.plot(MA2_2) plt.title(&#39;MA(1)=-0.4, MA(2)=0.3&#39;) # MA2_1 acf plot_acf(MA2_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,0], title =&#39;MA2_1 ACF&#39;) # MA2_2 acf plot_acf(MA2_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,1], title =&#39;MA2_2 ACF&#39;) # MA2_1 pacf plot_pacf(MA2_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,0], title =&#39;MA2_1 PACF&#39;) # MA2_2 pacf plot_pacf(MA2_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,1],title =&#39;MA2_2 PACF&#39; ) plt.show() 표본 ACF는 래그 2 이후 소멸함을 확인할 수 있다.반면에 표본 PACF는 점차적으로 감소하는 모양을 보이고 있다. 물론, 표본 ACF의 경우 고차의 래그에서도 영이 아닌 값이 있는 것처럼 보여 cut-off 특징이 잘 보이지 않을 수도 있으나 통계적 검정 또는 경험이 쌓이다 보면 이들이 비유의적이라는 것을 알게 될 것이다. 경험적으로 cut-off 특성은 ACF와 PACF를 동시에 보면서 상대적으로 판단하는 것이 유용할 때가 많다. 예를들면 PACF가 상대적으로 taper-off 특성을 가지고 있는 것을 쉽게 판단할 수 있을 것이다. 물론 실증분석에서는 적정 모형 설정 절차에 의하여 판단하는 것이 일반적이다. 2.6 q-차 이동평균모형(MA(q)모형) 이론적인 MA(q)확률과정의 분산은 다음과 같다. \\[ \\gamma_0 = (1+\\theta^2_1+\\cdots+\\theta^2_q)\\sigma^2_a \\] 자기공분산과 자기상관함수는 다음과 같다. \\[ \\gamma_k = (-\\theta_k + \\theta_1\\theta_{k+1}+\\theta_2\\theta_{k+2}+\\cdots+\\theta_{q-k}\\theta_{q})\\sigma^2_a, \\quad (k=1,2,\\cdots,q)\\\\ =0,\\quad (k&gt;q)\\\\ \\quad\\\\\\rho_k=(-\\theta_k + \\theta_1\\theta_{k+1}+\\theta_2\\theta_{k+2}+\\cdots+\\theta_{q-k}\\theta_{q})/(1+\\theta^2_1+\\cdots+\\theta^2_q), \\quad (k=1,2,\\cdots,q)\\\\ =0,\\quad (k&gt;q) \\] 그러므로 MA(q)모형에서 ACF는 래그 q 이후에 소멸하는 반면 PACF는 점차 감소하는 특성을 보이게 된다. 2.7 자기회귀 - 이동평균모형(ARMA(p,q) models) ‘자기회귀-이동평균모형’(Autoregressive Moving-Average Model; ARMA(p,q)모형)은 이름이 의미하는 것처럼 ‘혼합과정’(mixed process)이다. ARMA모형과 같은 혼합과정이 유용한 이유를 보기 위하여 다음과 같이 정의된 MA(\\(\\infty\\))모형으로 에로 들자. \\[ x_t = \\Theta(L)a_t, \\\\ \\Theta(L) = (1-\\theta L)(1+\\phi L + \\phi^2 L^2 + \\cdots) \\\\ =(1-\\theta L)/(1-\\phi L) \\] 이 때 \\(\\Theta(L)\\)는 \\(a(L)/b(L)\\)과 같이 래그다항식의 분수형태로 표현할 수 있다는 의미에서 ‘비율래그다항식’(rational lag polynomial)이라고 한다. 유사하게 AR(\\(\\infty\\))모형을 다음과 같이 표현해 보자. \\[ \\Phi(L)x_t = a_t \\\\ \\Phi(L)=(1-\\phi L)(1+\\theta L + \\theta^2 L^2 + \\cdots) \\\\ =(1-\\phi L)/(1-\\theta L) \\] 즉 \\(\\Phi(L)=b(L)/a(L)\\)이다. 따라서 다음과 같이 간결하게 표현할 수 있을 것이다. \\[ (1-\\phi L)x_t = (1-\\theta L)a_t \\\\ x_t = \\phi x_{t-1} + a_t - \\theta a_{t-1} \\] 위와 같은 식을 ARMA(1,1)과정이라고 부르며 이의 자기공분산은 다음과 같은 구조를 띄게 된다. \\[ \\gamma_1 = E(x_t x_{t-1}) \\approx f(AR,MA) \\\\ \\gamma_2 = E(x_t x_{t-2}) \\approx f(AR) \\] 즉, ARMA모형 중 AR부분이 래그 1만을 포함하는 경우 래그 1에서의 공분산 \\(\\gamma_1\\)은 자기회귀 및 이동평균 파라미터 모두의 함수이지만 그 이후 고차 래그에서의 공분산은 AR부분의 파라미터에만 의존하는 특성을 가지고 있다. 2.7.1 ARMA(1,1) 과정 ARMA(1,1)모형의 표현식은 다음과 같다. \\[ x_t = \\phi_1 x_{t-1} + a_t - \\theta_1 a_{t-1} \\] 안정성 조건은 \\(|\\phi_1| &lt; 1\\) 그리고 가역성 조건은 \\(|\\theta_1|&lt;1\\)이다. ARMA(1,1)모형의 분산과 공분산은 다음과 같이 계산할 수 있다. \\[ \\gamma_0 = \\phi_1 \\gamma_1 + \\sigma^2_a - \\theta_1 \\gamma_{xa} (-1) \\\\ \\gamma_1 = \\phi_1 \\gamma_0 + \\gamma_{xa}(1) - \\theta_1\\gamma_{xa}(0) = \\phi_1 \\gamma_0 - \\theta_1\\sigma^2_a \\\\ \\gamma_k = \\phi_1\\gamma_{k-1}, \\quad k\\ge2 \\] 이때, \\(\\gamma_{xa}(-1) = E(x_{t+1}a_t) = E[(\\phi_1 x_t + a_{t+1} - \\theta_1 a_t)a_t] = (\\phi_1 - \\theta_1)\\sigma^2_a\\)이므로 ARMA(1,1)과정의 분산과 자기공분산은 다음과 같다. \\[ \\gamma_0 = (\\frac{1 + \\theta^2_1 - 2 \\phi_1 \\theta_1}{1 - \\phi^2_1})\\sigma^2_a \\\\ \\gamma_1 = (\\frac{(1-\\phi_1\\theta_1)(\\phi_1-\\theta_1)}{1 - \\phi^2_1})\\sigma^2_a \\\\ \\gamma_k = \\phi_1\\gamma_{k-1}, \\quad k \\ge 2 \\] #### ARMA(1,1)모형의 자기상관함수(ACF) ARMA(1,1)모형의 ACF는 다음과 같다. \\[ \\rho_k = \\begin {cases} \\frac{(1-\\phi_1\\theta_1)(\\phi_1-\\theta_1)}{(1 + \\theta^2_1 - 2 \\phi_1 \\theta_1)}, \\quad k = 1 \\\\ \\phi_1\\rho_{k-1}, \\quad k\\ge2 \\end {cases} \\] 즉, \\(\\rho_1\\) 이후 ARMA(1,1)모형의 ACF는 AR 과정의 ACF와 같은 형태를 띄게 된다. 2.7.1.1 ARMA(1,1)모형의 편자기상관함수(PACF) ARMA(1,1)과정은 MA(1)과정을 특수한 경우로 포함하기 때문에 ARMA(1,1)과정의 PACF는 ACF처럼 지수적으로 점차 감소하며 그 모양은 \\(\\phi_1\\)과 \\(\\theta_1\\)의 부호와 크기에 따라 다르다. 그러므로 ACF와 PACF가 모두 점차 감소한다는 것은 ARMA 과정임을 의미한다고 볼 수 있다. 2.7.1.2 예제) ARMA(1,1)과정의 실현값 다음 예제는 시뮬레이션한 ARMA(1,1)과정들로 ARMA11_1과 ARMA11_2는 각각 \\(\\phi_1 = 0.9, \\ \\theta_1 = 0.5\\)와 \\(\\phi_1 = -0.4, \\ \\theta_1 = 0.8\\)로 설정하여 가정하고 있다. from statsmodels.tsa.arima_process import ArmaProcess plt.cla() fig, ax = plt.subplots(3,2,constrained_layout=True) # ARMA11_1 plt.subplot(3, 2, 1) arma11_1_ar_parm = np.array([1, -0.9]) arma11_1_ma_parm = np.array([1, -0.5]) ARMA11_1 = ArmaProcess(arma11_1_ar_parm, arma11_1_ma_parm).generate_sample(nsample=300) plt.plot(ARMA11_1) plt.title(&#39;ARMA(1,1) 1&#39;) # ARMA11_2 plt.subplot(3, 2, 2) arma11_2_ar_parm = np.array([1, 0.4]) arma11_2_ma_parm = np.array([1, -0.8]) ARMA11_2 = ArmaProcess(arma11_2_ar_parm, arma11_2_ma_parm).generate_sample(nsample=300) plt.plot(ARMA11_2) plt.title(&#39;ARMA(1,1) 2&#39;) # ARMA11_1 acf plot_acf(ARMA11_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,0], title =&#39;ARMA(1,1) 1 ACF&#39;) # ARMA11_2 acf plot_acf(ARMA11_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1,1], title =&#39;ARMA(1,1) 2 ACF&#39;) # ARMA11_1 pacf plot_pacf(ARMA11_1, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,0], title =&#39;ARMA(1,1) 1 PACF&#39;) # ARMA11_2 pacf plot_pacf(ARMA11_2, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2,1],title =&#39;ARMA(1,1) 2 PACF&#39; ) plt.show() 2.7.2 ARMA(p,q) 모형 일반적인 ARMA(p,q)모형은 다음과 같이 표현할 수 있다. \\[ x_t = \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + \\cdots + \\phi_p x_{t-p} +\\ a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2} - \\cdots - \\theta_q a_{t-q} \\\\ or \\\\ \\phi(L) x_t = \\theta(L) a_t \\\\ from \\\\ \\phi(L) = (1-\\phi_1 L - \\cdots - \\phi_p L^p)\\\\ and \\\\ \\theta (L) = (1-\\theta_1 L - \\cdots - \\theta_q L^q) \\] 자기공분산 함수는 다음과 같다. \\[ \\gamma_k = \\phi_1\\gamma_{k-1} + \\cdots + \\phi_p\\gamma_{k-p} + \\gamma_{xa}(k) - \\theta_1 \\gamma_{xa}(k-1) - \\cdots - \\theta_q\\gamma_{xa}(k-q) \\] 이때 \\(x_{t-k}\\)는 \\((t-k)\\)-시점까지 일어난 충격에만 영향을 받으므로 다음이 성립한다. \\[ \\gamma_{xa}(k) = E(x_{t-k}a_t) = 0 \\qquad k&gt;0 \\\\ \\gamma_{xa}(k) = E(x_{t-k}a_t) \\ne 0 \\qquad k \\le 0 \\\\ \\gamma_k = \\phi_1 \\gamma_{k-1}+\\cdots+\\phi_p \\gamma_{k-p} \\qquad k \\ge (q+1) \\] \\(x_t\\)의 분산은 다음과 같다. \\[ \\gamma_0 = \\phi_1\\gamma_1 + \\cdots + \\phi_p \\gamma_p + \\sigma^2_a - \\theta_1 \\gamma_{xa}(-1) - \\cdots - \\theta_q \\gamma_{xa}(-q) \\] 이를 바탕으로 ACF를 구하면 다음과 같다. \\[ \\rho_k = \\phi_1\\rho_{k-1}+\\cdots + \\phi_p \\rho_{k-p} \\qquad k\\ge(q+1) \\] 만약 안정성조건과 가역성조건을 모두 만족한다면, 표본 ACF와 표본 PACF 모두 점차 감소하는 모양을 띄게 된다. PACF는 지수적으로 감소하거나 점차 감소하는 sin곡선의 형태를 띄게 된다. 2.8 적정 ARMA(p,q)모형 선정 절차 - Diagnostic Checking Box and Jenkins(1976)은 적정 ARMA(p,q)모형을 선정하는 기준으로 ‘간결성’(parsimony)을 가장 큰 덕목 중 하나로 꼽았다. 즉, 가능한 초시의 추정 파라미터를 사용하여 데이터를 모형화하도록 권고하고 있다. AR(p)모형의 경우 적정한 차수 p를 선택하기 위하여 다음과 같은 ‘아카이케정보기준’(Akaike Information Criterion(AIC))을 사용할 수 있다. \\[ AIC(p) = T\\ln\\hat{\\sigma^2_a} + 2p \\quad or \\quad -2\\ln L(\\tilde{\\Theta})+2p \\] 단, \\(p\\)는 추정한 모형의 차수, \\(\\tilde{\\Theta}\\)는 최우추정값, \\(\\hat{\\sigma^2_a}\\)은 분산의 최우추정값,그리고 \\(T\\)는 유효표본크기를 나타낸다. 아카이케정보기준에 의한 적정모형 선정 방법은 AIC 값을 ‘최소화’하는 모형의 차수 \\(p\\)를 선택하는 것이다. Akaike는 또한 ’최소 AIC방법’을 베이즈방식으로 확장한 BIC(Baysian Information Criterion)을 제안했으며 이는 다음과 같다. \\[ BIC(p) = T\\ln\\hat{\\sigma}^2_a-(T-p)\\ln(1-\\frac{p}{T})+p\\ln T + p\\ln[(\\frac{\\hat{\\sigma}^2_x}{\\hat{\\sigma}^2_a}-1)/p] \\] 단, \\(\\hat{\\sigma}^2_x\\)는 모형화 하고자 하는 시계열 \\(x_t\\)의 분산이다. AIC와 마찬가지고 BIC값을 최소화하는 모형을 선택하게 된다. AIC와 유사하게 Schwartz(1978)은 AR(p)모형의 경우 다음과 같은 ‘쉬워츠 베이지언 정보기준’(Schwartz Bayesian Criterion; SC)를 제안하였다. \\[ SBC(p) = T\\ln\\hat{\\sigma}^2_a- p\\ln T \\] SC 또한 값을 최소화 하는 모형을 선택하게 된다. AIC는 SC보다 파라미터수를 과대식별하는 경향이 있는 것으로 알려지고 있다. ARMA(p,q)모형의 적정 차수 p,q를 선택하기 위해 Hannan &amp; Rissanen(1982)은 다음과 같은 기준을 사용하도록 제안하였다. \\[ T\\ln \\hat{\\sigma}^2_{p,q} + (p+q)\\ln T \\] \\(\\hat{\\sigma}^2_{p,q}\\)는 ARMA(p,q)모형의 잔차항의 분산이다. 마지막으로 모형추정 후 잔차항에 더이상 자기상관이 있는지 여부를 검정하기 위해서 Ljung-Box(1978)의 Q-통계량을 사용할 수 있을 것이다. \\[ Q = T(T+2)\\Sigma^k_{j=1} \\frac{\\hat{\\rho}^2_j}{(T-j)} \\sim \\chi^2(k-p-q) \\] 단, k는 적절하게 큰 숫자이며 \\(\\hat{\\rho}_j\\)는 표본 ACF이다. 잔차항이 자기상관이 없다는 귀무가설이 기각되면 이러한 잔차항을 초래한 ARMA(p,q)모형은 불만족한 것이 된다. 이외에도 개별 추정계수의 t-통게량도 모형선정에서 고려해야할 요인 중 하나이다. 2.8.1 diy 예제) 결과에서 확인해보기 res_arma11 = sm.tsa.arima.ARIMA(data, order=(1, 0, 1), ).fit() #p=1 d = 0 q = 1 임으로 ARMA(1,1) #print(res_arma11.summary()) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) print(&quot;AIC of ARMA(1,1) : &quot;, res_arma11.aic) ## AIC of ARMA(1,1) : -30386.615713351224 print(&quot;BIC of ARMA(1,1) : &quot;, res_arma11.bic) ## BIC of ARMA(1,1) : -30360.21914625497 print(&quot;Box-test of residuals : &quot;) ## Box-test of residuals : sm.stats.diagnostic.acorr_ljungbox(res_arma11.resid, lags=[10]) ## lb_stat lb_pvalue ## 10 9.408199 0.493851 res_arma22 = sm.tsa.arima.ARIMA(data, order=(2, 0, 2)).fit() #p=2 d = 0 q = 2 임으로 ARMA(1,1) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters. ## warn(&#39;Non-stationary starting autoregressive parameters&#39; ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters. ## warn(&#39;Non-invertible starting MA parameters found.&#39; print(&quot;AIC of ARMA(2,2) : &quot;, res_arma22.aic) ## AIC of ARMA(2,2) : -30383.406832359553 print(&quot;BIC of ARMA(2,2) : &quot;, res_arma22.bic) ## BIC of ARMA(2,2) : -30343.81198171517 print(&quot;Box-test of residuals : &quot;) ## Box-test of residuals : sm.stats.diagnostic.acorr_ljungbox(res_arma22.resid, lags=[10]) ## lb_stat lb_pvalue ## 10 8.793013 0.551854 2.9 ARMA 모형의 예측 2.9.1 ARMA (p,q) 모형의 예측의 기본원리 시계열 \\(x_t\\)가 ARMA(p,q)모형을 따를 때 이를 예측하는 문제를 생각하여보자. \\[ \\phi(L) x_t = \\theta(L) a_t \\\\ from \\\\ \\phi(L) = (1-\\phi_1 L - \\cdots - \\phi_p L^p)\\\\ \\theta (L) = (1-\\theta_1 L - \\cdots - \\theta_q L^q) \\\\ a_t \\sim WN(0,\\sigma^2_a) \\] 이때 AR다항식은 안정성 조건을, MA다항식은 가역성을 만족하는 것으로 가정한다. \\(a_t\\)는 보다싶이 백색잡음이다. 시계열 \\(x_t\\)의 최소평균제곱오차(minimum mean square error; MMSE) 예측치를 도출하는 데 필요한 기본원리를 한 마디로 요약하면 \\(x_{T+k}\\)의 MMSE 예측치 \\(\\hat{x}_t(k)\\)는 이의 조건부 기대값과 같다는 것이다. 즉, \\[ \\hat{x}_t(k) = E(x_{T+k}|x_T,x_{T-1},\\cdots) \\] 여기서 \\(\\hat{x}_t(k)\\)는 시점이 T이고 k-시점 후의 \\(x_{T+k}\\)에 대한 예측치를 나타낸다. 2.9.2 예측오차 k-단계 후 에측치의 예측오차(forecast error)는 다음과 같이 계산한다. \\[ e_T(k)=x_{T+k}-\\hat{x}_T(k)=\\Sigma^{k-1}_{j=0} \\ \\psi_j a_{T+k-j} \\] \\(E(e_t(k)|x_t,t\\le T) = 0\\)이므로 에측값은 불편추정량이며 분산은 다음과 같다. \\[ Var(e_T(k)) = \\sigma^2_a\\Sigma^{k-1}_{j=0}\\psi^2_j \\] 따라서 \\(a\\)-유의수준하에서 예측값의 신뢰구간은 다음과 같이 설정한다. \\[ \\hat{x}_T(k) \\pm N_{a/2} \\cdot \\sigma_a (1+\\Sigma^{k-1}_{j=1}\\psi^2_j)^{1/2} \\] 단, \\(N_{a/2}\\)는 \\(Pr(N&gt;N_{a/2}) = a/2\\)를 만족하는 표준 정규 변량이다. 실증분석에서는 보통 2-표준편차 신뢰구간 (\\(\\approx 95\\%\\) 신뢰구간)을 다음과 같이 설정한다. \\[ \\hat{x}_T(k) \\pm 2 \\cdot \\sigma_a [Var(e_T(k))]^{1/2} \\] 1-단계 후 예측오차는 \\(a_T(1)=x_{T+1}-\\hat{x}_T(1)=a_{T+1}\\)이므로 이들 오차 사이는 서로 무상관이다. 그러나 다음과 같은 k-단계 후 예측오차 (\\(k\\ge2\\))들은 이들 자신끼리 또는 서로 상관관계에 있다. \\[ e_T(k) = x_{T+k} - \\hat{x}_t(k) \\\\ = a_{T+k} + \\psi_1 a_{T+k-1}+\\cdots+ \\psi_{k-1} a_{T+1} \\\\ \\qquad \\\\ e_{T-s}(k) = x_{T+k-s} - \\hat{x}_{T-s}(k) \\\\ = a_{T+k-s} + \\psi_1 a_{T+k-s-1}+\\cdots+ \\psi_{k-1} a_{T-s+1} \\] 또한 같은 시점 T인 경우에도 리드가 서로 다른 예측오차들의 경우도 서로 상관관계에 있다. 예를 들어 \\[ Cov[e_T(1)e_T(2)] = \\psi_1 \\sigma^2_a \\ne 0 \\] 2.9.3 예제) 원-달러 환율변화율의 예측 2011년 부터 2020년 까지의 우리나라의 일별 원-달러 환율의 수익률을 ARMA모형으로 설정하여 추정하고 에측해보자. wd = yf.download(&quot;KRW=X&quot;,start=&quot;2000-01-01&quot;, end=&quot;2020-12-31&quot;) ## [*********************100%***********************] 1 of 1 completed wd = wd.resample(&quot;3M&quot;).ffill() wd[&quot;rtn&quot;]=wd[&quot;Adj Close&quot;].pct_change() #수익률 추가 wd_data = wd[&quot;rtn&quot;][1:] # 첫번째 열의 수익률은 nan이므로 제거 필요함. wd_data ## Date ## 2004-03-31 -0.019834 ## 2004-06-30 -0.009089 ## 2004-09-30 -0.004240 ## 2004-12-31 -0.128780 ## 2005-03-31 0.014363 ## ... ## 2019-12-31 -0.037906 ## 2020-03-31 0.057379 ## 2020-06-30 -0.019800 ## 2020-09-30 -0.025557 ## 2020-12-31 -0.064426 ## Freq: 3M, Name: rtn, Length: 68, dtype: float64 그림은 원게열과 이의 수익률을 예시하고 있다. plt.cla() fig, ax = plt.subplots(2,1,constrained_layout=True) plt.subplot(2, 1, 1) plt.plot(wd[&quot;Adj Close&quot;]) plt.title(&#39;WD&#39;) plt.subplot(2, 1, 2) plt.plot(wd[&quot;rtn&quot;]*100 ) plt.title(&#39;WD_Return(%)&#39;) plt.show() 여기서는 환율 자체를 안정시계열로 가정하고 분석을 진행하겠습니다. plt.cla() fig, ax = plt.subplots(2,1,constrained_layout=True) # acf plot_acf(wd[&quot;Adj Close&quot;], lags=10, use_vlines=True, zero = False, auto_ylims=True, ax=ax[0], title =&#39;WD ACF&#39;) # pacf plot_pacf(wd[&quot;Adj Close&quot;], lags=10, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1], title =&#39;WD PACF&#39;) plt.show() 전형적인 AR(1)의 ACF, PACF그림을 보여주고 있습니다. PACF가 래그 1 이후 cut-off하고 ACF는 지수적으로 감소하는 특성을 보이고 있습니다. 여기서는 ARMA(1,1) 모형을 활용하겠습니다. res_WD_arma11 = sm.tsa.arima.ARIMA(wd[&quot;Adj Close&quot;], order=(1, 0, 1), ).fit() print(res_WD_arma11.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Adj Close No. Observations: 69 ## Model: ARIMA(1, 0, 1) Log Likelihood -372.580 ## Date: 일, 09 10 2022 AIC 753.160 ## Time: 20:10:48 BIC 762.097 ## Sample: 12-31-2003 HQIC 756.706 ## - 12-31-2020 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## const 1108.7753 33.443 33.154 0.000 1043.227 1174.323 ## ar.L1 0.7983 0.091 8.742 0.000 0.619 0.977 ## ma.L1 0.0325 0.169 0.193 0.847 -0.299 0.364 ## sigma2 2824.1147 428.246 6.595 0.000 1984.767 3663.462 ## =================================================================================== ## Ljung-Box (L1) (Q): 0.00 Jarque-Bera (JB): 6.91 ## Prob(Q): 0.97 Prob(JB): 0.03 ## Heteroskedasticity (H): 0.52 Skew: 0.63 ## Prob(H) (two-sided): 0.12 Kurtosis: 3.92 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). print(&quot;\\n\\n\\n&quot;) print(&quot;AR Roots : &quot;, res_WD_arma11.arroots) ## AR Roots : [1.25268202] print(&quot;MA Roots : &quot;, res_WD_arma11.maroots) ## MA Roots : [-30.72466872] print(&quot;Inverted AR Roots : &quot;, res_WD_arma11.arroots**(-1)) ## Inverted AR Roots : [0.79828718] print(&quot;Inverted MA Roots : &quot;, res_WD_arma11.maroots**(-1)) ## Inverted MA Roots : [-0.03254714] print(&quot;Mean Squared Error (MSE) : &quot;, res_WD_arma11.mse) ## Mean Squared Error (MSE) : 2887.043173769232 print(&quot;=&quot;*50) ## ================================================== print(&quot;box test on residuals : &quot;) #res_WD_arma11.test_serial_correlation(&#39;ljungbox&#39;) ## box test on residuals : sm.stats.diagnostic.acorr_ljungbox(res_WD_arma11.resid, lags=10) ## lb_stat lb_pvalue ## 1 0.000848 0.976762 ## 2 0.881060 0.643695 ## 3 1.080017 0.781900 ## 4 2.738673 0.602464 ## 5 2.915244 0.713051 ## 6 2.915701 0.819350 ## 7 3.049872 0.880351 ## 8 4.546201 0.804793 ## 9 6.597491 0.678946 ## 10 7.497217 0.677817 AR 모형이 더 적합해보입니다만, 그대로 진행하겠습니다. 예측을 진행하겠습니다. #print(res_WD_arma11.forecast(10)) # 분산이 없음 forecast_10 = res_WD_arma11.get_forecast(10) forecast_10.predicted_mean # 예측 평균 ## 2021-03-31 1093.830924 ## 2021-06-30 1096.845390 ## 2021-09-30 1099.251800 ## 2021-12-31 1101.172806 ## 2022-03-31 1102.706320 ## 2022-06-30 1103.930505 ## 2022-09-30 1104.907756 ## 2022-12-31 1105.687883 ## 2023-03-31 1106.310648 ## 2023-06-30 1106.807794 ## Freq: 3M, Name: predicted_mean, dtype: float64 forecast_10.conf_int(alpha=0.05) #알파값에 따른 신뢰구간간 ## lower Adj Close upper Adj Close ## 2021-03-31 989.673735 1197.988114 ## 2021-06-30 961.429600 1232.261180 ## 2021-09-30 947.233007 1251.270593 ## 2021-12-31 939.460387 1262.885225 ## 2022-03-31 935.108753 1270.303887 ## 2022-06-30 932.688036 1275.172974 ## 2022-09-30 931.382464 1278.433048 ## 2022-12-31 930.723371 1280.652395 ## 2023-03-31 930.435119 1282.186177 ## 2023-06-30 930.354162 1283.261426 이를 그래프로 나타내겠습니다. import seaborn as sns plt.cla() fig, ax = plt.subplots(constrained_layout=True) fig.set_size_inches(15, 15) # 신뢰구간 ax.fill_between( forecast_10.conf_int(alpha=0.05).index, #날짜 forecast_10.conf_int(alpha=0.05)[&quot;upper Adj Close&quot;], #상한 forecast_10.conf_int(alpha=0.05)[&quot;lower Adj Close&quot;], #하한 facecolor=&#39;green&#39;, interpolate=True, alpha = 0.3) # 투명도 # 평균 ax.plot(forecast_10.predicted_mean, &#39;g&#39;) # x축, y축 제목 ax.set_xlabel(&#39;date&#39;, fontsize = 10) ax.set_ylabel(&#39;WD&#39;, fontsize = 10) # x축, y축 폰트 사이즈 ax.tick_params(axis = &#39;x&#39;, labelsize = 5) ax.tick_params(axis = &#39;y&#39;, labelsize = 5) # 년도 데이터 전체 표출 ax.set_xticks(forecast_10.conf_int(alpha=0.05).index); plt.show() "],["불안정적-시계열모형의-추정과-예측.html", "3 불안정적 시계열모형의 추정과 예측 3.1 시작에 앞서 python을 사용하기 위한 설정 3.2 불안정시계열모형 3.3 확률보행모형 3.4 Integrated Moving-Average(IMA)모형 3.5 ARIMA(p,d,q)과정 3.6 베버리지-넬슨 분해 3.7 Hodric-Prescott 필터 3.8 불안정시계열의 예측 3.9 Python을을 이용한 예측 예제", " 3 불안정적 시계열모형의 추정과 예측 3.1 시작에 앞서 python을 사용하기 위한 설정 다음은 python을 불러오기 위한 것입니다. 본인의 파이썬 경로를 넣으실 수도 있겠지만, 편의를 위하여 포함되어 있는 파일을 사용하시길 추천드립니다. knitr::opts_chunk$set(echo = TRUE) knitr::knit_engines$set(python = reticulate::eng_python) library(&quot;reticulate&quot;) use_python(&quot;../python&quot;) #본인의 파이썬 경로를 넣어야만 합니다. import pandas as pd import numpy as np import statsmodels.api as sm import yfinance as yf import matplotlib.pyplot as plt 3.2 불안정시계열모형 금융시계열분석에서 흔히 접하는 자료는 불안정시계열(nonstationary time series)이다. 예를 들어, 주가, 주당이익(earnings per share), 배당금, 환율, 국고채 이자율, 소비자물가지수 등등 가공하지 않은 대부분의 원계열들이 불안정 시계열에 속한다. 불안정시계열은 안정성 조건을 만족하지 않으며 일반적으로 결정적(deterministic) 또는 확률적 추세(stochastic trend)를 갖는다. 추세가 있는 불안정시계열은 추세를 제거하고 움직임을 분석하는 경우가 많다. 따라서 추세를 제거하는 몇 가지 방법도 함께 살펴볼 것이다. 다음 그림은 불안정시계열의 대표적인 예로 삼성전자의 일별주가를 예시한 것이다. samsung = yf.download(&quot;005930.KS&quot;,start=&quot;2019-01-05&quot;, end=&quot;2021-12-28&quot;) ## [*********************100%***********************] 1 of 1 completed plt.cla() samsung[&quot;Adj Close&quot;].plot.line() plt.show() samsung ## Open High Low Close Adj Close Volume ## Date ## 2019-01-07 38000.0 38900.0 37800.0 38750.0 34936.316406 12748997 ## 2019-01-08 38000.0 39200.0 37950.0 38100.0 34350.281250 12756554 ## 2019-01-09 38650.0 39600.0 38300.0 39600.0 35702.667969 17452708 ## 2019-01-10 40000.0 40150.0 39600.0 39800.0 35882.972656 14731699 ## 2019-01-11 40350.0 40550.0 39950.0 40500.0 36514.082031 11661063 ## ... ... ... ... ... ... ... ## 2021-12-21 77900.0 78300.0 77500.0 78100.0 76878.984375 14245298 ## 2021-12-22 78900.0 79400.0 78800.0 79400.0 78158.656250 17105892 ## 2021-12-23 79800.0 80000.0 79300.0 79900.0 78650.843750 13577498 ## 2021-12-24 80200.0 80800.0 80200.0 80500.0 79241.460938 12086380 ## 2021-12-27 80600.0 80600.0 79800.0 80200.0 78946.156250 10783368 ## ## [736 rows x 6 columns] 현대재무금융이론론에서는 주가를 예측함에 있어서 일정한 이론모형을 설정하고 애널리스트들의 주당이익 예측치나 무위험 이자율과정에 관한 정보를 추가로 활용하기도 한다. 순수하게 시계열분석 측면에서도 예측하고자 하는 주가 뿐만 아니라 국내외의 주요 경제금융변수들을 함께 고려한 모형을 이용하는 방법도 있다. 이처럼 factor model (요인모형)이나 벡터시계열을 이용한 예측은 후술하기로 하고 여기에서는 단일 시게열만을 고려한 불안정시계열모형의 에측기법을 살펴보기로 한다. 3.3 확률보행모형 불안정 확률과정의 가장 간단한 예로 AR(1)모형의 계수 \\(\\phi\\)가 1인 ‘확률보행모형’(Random Walk Model, 이하 RW)을 생각하여 보자. RW모형은 AR다항식의 근이 1, 즉 단위근을 갖는 경우이며 안정성조건을 만족하지 않는다. 불안정 확률과정은 ‘적분과정’(integrated process)이라고도 하는데, RW과정에서 등호 오른쪽의 과거값을 반복 대입하여 다음과 같이 표현하면 그 이유를 알 수 있다. \\[ x_t = \\mu + x_{t-1} + a_t = \\mu + \\Sigma^\\infty_{j=0} a_{t-j}= \\mu + a_t + \\Sigma^\\infty_{j=1} a_{t-j}, \\quad a_t\\sim (0,\\sigma^2) \\] \\(\\mu\\)는 표류항(rate of drift)라고 부른다. 앞으로는 0으로 가정할 것이다. \\(x_t\\)의 분산은 유한한 상수가 아니므로 안정성 조건을 위배하며 따라서 불안정 시계열이 된다. 또한 \\((1-L)x_t = a_t\\)로 표현해보면 AR 다항식이 하나의 단위근을 가지므로 불안정적임을 확인할 수 있다. 현시점의 \\(x_t\\)값은 현 시점을 포함하여 과거의 모든 잔차항들의 합계이므로 이는 마치 \\(\\{a_t\\}\\)계열을 적분한 것과 같다. 따라서, \\(x_t\\)를 적분과정이라고 부른다. 물론 \\(x_t\\)를 한 번 차분하면, \\(a_t\\), 즉 안정적 과정이므로 \\(x_t\\)를 ‘I(1)과정’,즉 한 번 차분하면 안정적 시계열이 되는 ’1차 적분과정’이라고 표현한다. 유사하게 백색잡음은 그 자체가 안정적 과정이므로 ’I(0)과정’이라고 표현한다. 또 하나의 특징은 \\(\\partial x_t / \\partial a_{t-j}, \\ j=0,1,2,\\cdots\\)의 크기가 모두 1로 같으며 특정 시점에서의 충격은 \\(x_t\\)의 ’수준’에 항구적인 영향을 미친다는 것이다. AR(1)과 같은 안정적 시계열 모형서 충격이 시간의 경게에 따라 그 영향력이 지수적으로 감소하는 것과 대조를 이룬다. 3.3.1 예제) 확률보행과정 Sample ACF와 Sample PACF 다음은 확률보행과정의 시뮬레이션값과 표본 ACF, 표본 PACF이다. from statsmodels.tsa.arima_process import ArmaProcess from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf plt.cla() fig, ax = plt.subplots(3,1, constrained_layout=True) plt.subplot(3, 1, 1) rw = ArmaProcess(np.array([1, -1]), np.array([1])).generate_sample(nsample=500) plt.plot(rw) plt.title(&#39;Random walk without a drift&#39;) #acf plot_acf(rw, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1], title =&#39;RW ACF&#39;) #pacf plot_pacf(rw, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2],title =&#39;RW PACF&#39; ) plt.show() 3.4 Integrated Moving-Average(IMA)모형 x_t가 단위근을 가지고 있으며 동시에 이동평균한을 가지고 있는 다음과 같은 불안정 시계열모형을 생각해 보자. \\[ (1-L)x_t = a_t - \\theta a_{t-1} \\] 이 때 적분차수는 1인 반면 자기회구부분은 없으므로 \\(x_t\\)를 IMA(1,1)과정이라고 한다.(ARIMA(0,1,1)) 이러한 모형은 불안정 시계열을 두 개의 부분, 즉 신호(signal)와 잡음으로 나누는 예제에서 흔히 볼 수 있다. 측정된 데이터 \\(x_t\\)로부터 추세와 사이클부분으로 분해하는 문제를 보통 신호추출(signal extraction)이라고 부른다. (이떄 추세와 사이클 부분의 공분산은 0을 가정한다.) \\[ x_t = \\tau_t+c_t,\\quad c_t \\sim (0,\\sigma^2_c) \\\\ \\tau_t = \\tau_{t-1} + v_t, \\quad v_t \\sim (0,\\sigma^2_v) \\] 에서 식을 다음과 같이 변형할 수 있을 것이다. \\[ (1-L)x_t = \\Delta x_t = v_t + c_t - c_{t-1} = a_t - \\theta a_{t-1} \\] 이때, \\(x_t\\)의 분산 공분산을 고려하면 다음과 같다. \\[ Var(\\Delta x_t) = \\sigma^2_v + 2 \\sigma^2_c \\\\ Cov(\\Delta x_t,\\Delta x_{t-1}) = - \\sigma^2_c \\] 따라서 1차 자기상관계수는 다음과 같다. \\[ -0.5 \\le \\rho_1 = \\frac{- \\sigma^2_c}{\\sigma^2_v + 2 \\sigma^2_c} \\le 0 \\] 그러므로 역으로 어떤 시계열의 차분과정이 래그 1에서 음의 자기상관을 보이는 경우 신호와 잡음의 합으로 모형설정 할 수 있음을 알 수 있다. 3.4.1 IMA(1,1)과정의 Sample ACF와 Sample PACF from statsmodels.tsa.arima_process import ArmaProcess from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.tsatools import unintegrate, unintegrate_levels # r과는 달리 차분 역과정 함수 사용 plt.cla() fig, ax = plt.subplots(5,1, constrained_layout=True) plt.subplot(5,1,1) ma1_1_ar_parm = np.array([1]) ma1_1_ma_parm = np.array([1, - 0.5]) MA1_1 = ArmaProcess(ma1_1_ar_parm, ma1_1_ma_parm).generate_sample(nsample=501) #ima11 ima_11 = unintegrate(MA1_1, [1]) plt.plot(ima_11) #acf plot_acf(ima_11, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1], title =&#39;IMA(1,1) MA(1) = -0.5, ACF&#39;) #pacf plot_pacf(ima_11, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[2],title =&#39;IMA(1,1) MA(1) = -0.5, PACF&#39; ) #diff plt.subplot(5,1,4) diffed_ima_11 = np.diff(ima_11, 1) plt.plot(diffed_ima_11) #acf plot_acf(diffed_ima_11, lags=40, use_vlines=True, zero = False, auto_ylims=True, ax=ax[4], title =&#39;first diffference of IMA(1,1) MA(1) = -0.5, ACF&#39;) plt.show() unintegrate 함수 3.5 ARIMA(p,d,q)과정 일반적인 ARIMA(p,d,q)은 다음과 같이 쓸 수 있다. \\[ \\phi(L)(1-L)^d x_t = \\theta(L)a_t \\\\ or \\\\ y&#39;_{t} = c + \\phi_{1}y&#39;_{t-1} + \\cdots + \\phi_{p}y&#39;_{t-p} + \\theta_{1}\\varepsilon_{t-1} + \\cdots + \\theta_{q}\\varepsilon_{t-q} + \\varepsilon_{t} \\] 3.6 베버리지-넬슨 분해 해당논문 실증분석에서 다루는 경제 및 금융시계열들은 불안정 시계열인 경우가 많으며 이들을 직접 다루기보다는 이들로부터 불안정부분인 추세를 제거하고 남은 나머지인 안정적인 계열을 계산하여 분석하는 것이 보통이다. 이와 관련하여 많이 인용되는 추세제거방법 중 하나는 베버리지-넬슨 분해(Beveridge-Nelson decomposition; BN분해)이다. 이는 일차 차분 후 안정적인 시게열은 확률보행을 따르는 추세부분과 사이클부분으로 분해할 수 있음을 보였다. 이 때 안정적 과정인 사이클부분은 추세로 돌아가려는 예측가능한 모멘텀을 가질 수도 있으나 관측값이 추세부분에 근접함에 따라 사라지게 된다. BN 분해를 예시하기 위하여 다음과 같은 IMA(1,1) 과정을 두 개의 부분으로 분해하는 과정을 살펴보자. \\[ x_t = x_{t-1} + a_t - \\theta a_{t-1} \\\\ = x_{t-2}+(a_{t-1} - \\theta a_{t-2}) + (a_{t} - \\theta a_{t-1}) \\\\ = \\Sigma^t_{j=1} a_j - \\theta \\Sigma^{t-1}_{j=1} a_j \\quad (\\ x_0 = a_0 = 0 \\ 이라고 \\ 가정) \\\\ = (1-\\theta)(\\Sigma^t_{j=1}a_j)+\\theta a_t \\] 이때 \\(\\tau_t = (1-\\theta)(\\Sigma^t_{j=1}a_j)\\) 그리고 \\(c_t = \\theta a_t\\)라고 정의하면 다음과 같이 정리할 수 있다. \\[ x_t = \\tau_t + c_t \\\\ \\tau_t = \\tau_{t-1} + (1-\\theta)a_t = \\tau_{t-1}+v_t \\\\ c_t = \\theta a_t = \\epsilon_t \\] 이때 두 부분의 확률오차항 \\(v_t\\)와 \\(\\epsilon_t\\)는 모두 \\(a_t\\)에 비례하며 따라서 완전상관관계에 있다. 보다 일반적인 ARIMA(p,1,q) 과정을 따르는 \\(x_t\\)를 \\(\\tau_t\\)와 \\(c_t\\)로 분해하는 경우를 생각해 보자. AR과 MA 래그 다항식이 각각 안정ㅈ성 조건과 가역성 조건을 만족하는 경우 \\(x_t\\)의 차분과정인 \\(\\Delta x_t\\)는 다음과 같이 월드 표현식으로 쓸 수 있다. \\[ \\Delta x_t = \\mu + \\psi (L) a_t = \\mu + \\Sigma ^\\infty_{j=0} \\psi_j a_{t-j} = \\mu + e_t \\] 단, \\(\\mu\\)는 \\(\\Delta x_t\\)의 결정적(비확률적) 부분으로서 후에 보는 것처럼 추세부분인 \\(\\tau_t\\)의 표류항이된다. 이를 변형하면 \\(x_{t+k}\\)는 다음과 같은 식으로 표현할 수 있다. \\[ x_{t+k} = x_t + \\mu \\cdot k + \\Sigma^k_{i=1} e_{t+i} \\] 이 때 \\(e_t=(a_t + \\psi_1 a_{t-1} \\cdots)\\) 임을 상기하면 \\[ \\Sigma^k_{i=1} e_{t+i} = \\Sigma^k_{i=1}a_{t+i} + \\psi_1 \\Sigma^k_{i=1}a_{t-1+i} + \\psi_2 \\Sigma^k_{i=1}a_{t-2+i} + \\cdots \\] 이 성립하고, $E_t a_{t+i} = 0 $이므로 t-시점에서 \\(x_{t+k}\\)에 대한 예측값은 다음과 같다. \\[ E_t x_{t+k} = \\mu \\cdot k + x_t + (\\Sigma^k_{i=1} \\psi_i)a_t + (\\Sigma^{k+1}_{i=2} \\psi_i)a_{t-1} + (\\Sigma^{k+2}_{i=3} \\psi_i)a_{t-2} + \\cdots \\] BN 분해에서 추세부분 \\(\\tau_t\\)는 k가 무한히 커질 때 예측값 \\(E_t(x_{t+k}-\\mu \\cdot k)\\)가 점근하는 값으로 정의된다. 따라서 추세부분 \\(\\tau_t\\)는 다음과 같이 위의 식에서 오른쪽 항들 중 첫번째를 제외한 모든 항들의 합과 같다. \\[ x_t + (\\Sigma^\\infty_{i=1} \\psi_i)a_t + (\\Sigma^{\\infty}_{i=2} \\psi_i)a_{t-1} + (\\Sigma^{\\infty}_{i=3} \\psi_i)a_{t-2} + \\cdots \\] 3.7 Hodric-Prescott 필터 불안정 시계열로부터 추세를 제거하는데 사용하는 또 다른 방법은 ‘Hodric-Prescott 필터’가 있다. 관측치가 \\(\\{x_t\\}^T_{t=1}\\)로 주어졌을 때 HP 필터 분해는 다음의 제곱합을 최소화하는 추세 \\(\\{\\tau_t\\}^T_{t=1}\\)를 구하는 것이다. \\[ S(\\tau_t)=(1/T)\\Sigma^T_{t=1}(x_t-\\tau_t)^2 + (\\lambda/T) \\Sigma^{T-1}_{t=2}[(\\tau_{t+1}-\\tau_t)-(x_t-\\tau_t)]^2 \\] \\(\\lambda\\)는 임의의 상수로 추세항에 변동을 허용하는데 따른 ’비용’을 나타내는 항이다. \\(\\lambda\\)를 크게 할수록 추세는 스무드하게 되며 극단적으로 이를 무한대로 놓으면 \\(\\tau_t\\)는 선형추세에 접근한다. 즉, \\(\\lambda\\)를 아주 크게 놓으면 \\((\\Delta\\tau_{t+1}-\\Delta \\tau_t)\\)가 매우 작게 되는 것이다. 반면 이를 0으로 두면 추세가 관측치와 동일하게 된다. 즉, \\(x_t = \\tau_t\\)이다. Hodric and Prescott(1984)는 연간, 분기별 그리고 월별 데이터의 경우 \\(\\lambda\\)를 각각 100, 1,600 그리고 14,400으로 둘 것을 제안하였다. 식을 최소화하는 \\(\\{x_t\\}^T_{t=1}\\)를 찾는 것을 수치최소화하는 방법으로 접근하는 것은 매우 어렵다. 왜냐하면 T-1개의 파라미터를 미지수로 놓고 이를 추정해야 하기 때문이다. 실무에서는 수치적인 방법이 아니라 대수적인 방법에 의하야 확률적 추세를 구한다. 즉, 목적함수의 극소화 조건을 직접 유도한 뒤 확률적 추세 \\(\\{x_t\\}^T_{t=1}\\)를 닫힌 해의 형태로 구하고 형렬연산을 적용하여 계산하게 된다. 3.7.1 예제)HP 필터 분해 BN 분해와 HP 분해 또는 기타 다른 대안적 방법이 있다고 했을 때 어느 방법을 적용하는 것이 최선인가에 대하여는 아직 이론이 있으며 연구의 목적에 따라 적절한 선택을 할 필요가 있다. 다만, HP필터를 확률보행과정을 따르는 시계열에 적용하는 경우에도 (존재하지 않는) 사이클을 분리해내는 경우도 있으므로 이 방법을 사용할 때는 특히 유의하여야 한다. 다음 예제는 1959년부터 2009년 3분기 까지 분기별 실질 GDP에 관한 분석이다. dta = sm.datasets.macrodata.load_pandas().data index = pd.period_range(&#39;1959Q1&#39;, &#39;2009Q3&#39;, freq=&#39;Q&#39;) dta.set_index(index, inplace=True) cycle, trend = sm.tsa.filters.hpfilter(dta.realgdp, 1600) # 분기별 데이터 이므로 1600 설정 gdp_decomp = dta[[&#39;realgdp&#39;]] gdp_decomp[&quot;cycle&quot;] = cycle ## &lt;string&gt;:1: SettingWithCopyWarning: ## A value is trying to be set on a copy of a slice from a DataFrame. ## Try using .loc[row_indexer,col_indexer] = value instead ## ## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy gdp_decomp[&quot;trend&quot;] = trend ## &lt;string&gt;:1: SettingWithCopyWarning: ## A value is trying to be set on a copy of a slice from a DataFrame. ## Try using .loc[row_indexer,col_indexer] = value instead ## ## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy plt.cla() fig, ax = plt.subplots(2,1, constrained_layout=True) gdp_decomp[[&quot;realgdp&quot;, &quot;trend&quot;]][&quot;2000-03-31&quot;:].plot(ax=ax[0]) gdp_decomp[[&quot;cycle&quot;]][&quot;2000-03-31&quot;:].plot(ax=ax[1]) plt.show() 다음은 KOSPI의 월별 종가를 이용하여 HP 분해를 실행한 결과이다. kospi = yf.download(&quot;^KS11&quot;,start=&quot;2000-01-04&quot;, end=&quot;2021-12-31&quot;) ## [*********************100%***********************] 1 of 1 completed kospi = kospi.resample(&#39;M&#39;).ffill() cycle, trend = sm.tsa.filters.hpfilter(kospi[&#39;Adj Close&#39;], 14400) # 월별 데이터 이므로 14400 설정 kospi_decomp = kospi[[&#39;Adj Close&#39;]] kospi_decomp[&quot;cycle&quot;] = cycle ## &lt;string&gt;:1: SettingWithCopyWarning: ## A value is trying to be set on a copy of a slice from a DataFrame. ## Try using .loc[row_indexer,col_indexer] = value instead ## ## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy kospi_decomp[&quot;trend&quot;] = trend ## &lt;string&gt;:1: SettingWithCopyWarning: ## A value is trying to be set on a copy of a slice from a DataFrame. ## Try using .loc[row_indexer,col_indexer] = value instead ## ## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy plt.cla() fig, ax = plt.subplots(2,1, constrained_layout=True) kospi_decomp[[&quot;Adj Close&quot;, &quot;trend&quot;]][&quot;2010-01-01&quot;:].plot(ax=ax[0]) kospi_decomp[[&quot;cycle&quot;]][&quot;2010-01-01&quot;:].plot(ax=ax[1]) plt.show() 3.8 불안정시계열의 예측 3.8.1 ARIMA(p,d,q)모형의 MMSE 예측 다음과 같이 일반적인 ARIMA(p,d,q)모형 \\((d\\ne0)\\)을 예측하는 방법을 생각해보자. \\[ \\phi(L)(1-L)^d x_t = \\theta(L)a_t \\] 수작업으로 계산할 일은 거의 없을 것이므로 결과만 보인다. \\[ x_{t+k} = \\Sigma^\\infty_{j=1} \\pi_{k-j+1} + \\Sigma^\\infty_{i=0}\\psi_i a_{t+k-i} \\] \\(\\pi^{(k)}_j = \\Sigma^{k-1}_{i=0} \\pi_{k-1+j-i}\\psi_i\\) 따라서 \\(E(a_{T+j}|x_t\\le T)=0(j&gt;0)\\)임을 상기하면 k-단계 후 예측값은 다음과 같이 계산할 수 있다. \\[ \\hat{x}_T(k)=E(x_{T+k}|x_T,x_{T-1},\\cdots) = \\Sigma^\\infty_{j=1} \\pi^{(k)}x_{T-j+1} \\] 이 때 예측오차는 다음과 같다. \\[ e_T(k)=x_{T+k}-\\hat{x}_T(k) = \\Sigma^{k-1}_{j=0}\\psi_j a_{T+k-j} \\] ARIMA(p,d,q)모형의 MMSE 예측오차는 안정적 과정, 즉 ARIMA(p,0,q)모형의 MMSE 예측오차와 동일한 모양을 가지고 있는 것을 유념하자. 3.9 Python을을 이용한 예측 예제 2011년 부터 2020년 까지의 삼성전자의 일별 종가를 ARIMA모형으로 설정하여 추정하고 에측해보자. wd = yf.download(&quot;005930.KS&quot;,start=&quot;2000-01-01&quot;, end=&quot;2020-12-31&quot;) #wd = wd.resample(&quot;3M&quot;).ffill() ## [*********************100%***********************] 1 of 1 completed 그림은 일별 종가를 나타내고 있다. plt.cla() fig, ax = plt.subplots(1,1,constrained_layout=True) plt.subplot(1, 1, 1) plt.plot(wd[&quot;Adj Close&quot;]) plt.title(&#39;SAMSUNG Adj Close&#39;) plt.show() plt.cla() fig, ax = plt.subplots(2,1,constrained_layout=True) # acf plot_acf(wd[&quot;Adj Close&quot;], lags=10, use_vlines=True, zero = False, auto_ylims=True, ax=ax[0], title =&#39;WD ACF&#39;) # pacf plot_pacf(wd[&quot;Adj Close&quot;], lags=10, use_vlines=True, zero = False, auto_ylims=True, ax=ax[1], title =&#39;WD PACF&#39;) plt.show() res_WD_arima110 = sm.tsa.arima.ARIMA(wd[&quot;Adj Close&quot;], order=(1, 1, 0), ).fit() ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. ## self._init_dates(dates, freq) print(res_WD_arima110.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Adj Close No. Observations: 5280 ## Model: ARIMA(1, 1, 0) Log Likelihood -39203.142 ## Date: 일, 09 10 2022 AIC 78410.283 ## Time: 20:11:07 BIC 78423.426 ## Sample: 0 HQIC 78414.877 ## - 5280 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## ar.L1 0.0363 0.006 5.855 0.000 0.024 0.048 ## sigma2 1.651e+05 1263.699 130.686 0.000 1.63e+05 1.68e+05 ## =================================================================================== ## Ljung-Box (L1) (Q): 0.01 Jarque-Bera (JB): 26340.34 ## Prob(Q): 0.93 Prob(JB): 0.00 ## Heteroskedasticity (H): 19.67 Skew: 0.48 ## Prob(H) (two-sided): 0.00 Kurtosis: 13.90 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). print(&quot;\\n\\n\\n&quot;) print(&quot;AR Roots : &quot;, res_WD_arima110.arroots) ## AR Roots : [27.56137516] print(&quot;MA Roots : &quot;, res_WD_arima110.maroots) ## MA Roots : [] print(&quot;Inverted AR Roots : &quot;, res_WD_arima110.arroots**(-1)) ## Inverted AR Roots : [0.03628266] print(&quot;Inverted MA Roots : &quot;, res_WD_arima110.maroots**(-1)) ## Inverted MA Roots : [] print(&quot;Mean Squared Error (MSE) : &quot;, res_WD_arima110.mse) ## Mean Squared Error (MSE) : 169167.51874499713 print(&quot;=&quot;*50) ## ================================================== print(&quot;box test on residuals : &quot;) #res_WD_arima110.test_serial_correlation(&#39;ljungbox&#39;) ## box test on residuals : sm.stats.diagnostic.acorr_ljungbox(res_WD_arima110.resid, lags=[5]) ## lb_stat lb_pvalue ## 5 13.517299 0.018985 예측을 진행하겠습니다. #print(res_WD_arma11.forecast(10)) # 분산이 없음 forecast_10 = res_WD_arima110.get_forecast(100) ## C:\\Users\\user\\Desktop\\FINTIM~1\\python\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`. ## return get_prediction_index( forecast_10.predicted_mean # 예측 평균 ## 5280 78752.215670 ## 5281 78755.667230 ## 5282 78755.792462 ## 5283 78755.797005 ## 5284 78755.797170 ## ... ## 5375 78755.797176 ## 5376 78755.797176 ## 5377 78755.797176 ## 5378 78755.797176 ## 5379 78755.797176 ## Name: predicted_mean, Length: 100, dtype: float64 forecast_10.conf_int(alpha=0.05) #알파값에 따른 신뢰구간간 ## lower Adj Close upper Adj Close ## 5280 77955.719249 79548.712091 ## 5281 77608.634465 79902.699995 ## 5282 77342.040790 80169.544133 ## 5283 77118.187072 80393.406939 ## 5284 76921.446854 80590.147487 ## ... ... ... ## 5375 70661.067122 86850.527230 ## 5376 70618.983948 86892.610405 ## 5377 70577.117308 86934.477045 ## 5378 70535.463894 86976.130459 ## 5379 70494.020482 87017.573871 ## ## [100 rows x 2 columns] 이를 그래프로 나타내겠습니다. import seaborn as sns plt.cla() fig, ax = plt.subplots(constrained_layout=True) fig.set_size_inches(15, 15) # 신뢰구간 ax.fill_between( forecast_10.conf_int(alpha=0.05).index, forecast_10.conf_int(alpha=0.05)[&quot;upper Adj Close&quot;]/100, #상한 forecast_10.conf_int(alpha=0.05)[&quot;lower Adj Close&quot;]/100, #하한 facecolor=&#39;green&#39;, interpolate=True, alpha = 0.3) # 투명도 # 평균 ax.plot( forecast_10.predicted_mean/100 , &#39;g&#39;) # x축, y축 제목 ax.set_xlabel(&#39;date&#39;, fontsize = 10) ax.set_ylabel(&#39;WD&#39;, fontsize = 10) # x축, y축 폰트 사이즈 ax.tick_params(axis = &#39;x&#39;, labelsize = 1) ax.tick_params(axis = &#39;y&#39;, labelsize = 5) # 년도 데이터 전체 표출 ax.set_xticks(forecast_10.conf_int(alpha=0.05).index); plt.show() "],["추세와-단위근.html", "4 추세와 단위근 4.1 시작에 앞서 python을 사용하기 위한 설정 4.2 추세모형 4.3 Dickey-Fuller 단위근 검정 4.4 필립스-페론(Phillips-Perron) 단위근 검정 4.5 유사회귀분석 4.6 단위근이 있는 시계열의 유사추세 및 사이클 4.7 시간추세 안정적 시계열과 차분안정적 시계열의 선택문제", " 4 추세와 단위근 4.1 시작에 앞서 python을 사용하기 위한 설정 다음은 python을 불러오기 위한 것입니다. 본인의 파이썬 경로를 넣으실 수도 있겠지만, 편의를 위하여 포함되어 있는 파일을 사용하시길 추천드립니다. import pandas as pd import arch import numpy as np import statsmodels.api as sm import yfinance as yf import matplotlib.pyplot as plt 4.2 추세모형 추세란 보통 어떤 시계열이 단기보다는 장기적으로 움직이는 패턴을 말한다. 시계열 분석에서 추세는 일정한 모형을 전제로 하고 정의한다. 예를 들어 ARMA 유형의 시계열모형을 전제로 추세를 정의할 수도 있고, 성장곡선과 같은 비선형모형을 전제로 할 수도 있다. 시계열모형에서 어떻게 추세를 모형화하는가는 장기 out-of-sample 예측에 있어서 지배적인 결과를 초래하므로 실제로 데이터의 모형을 설정하기 전에 추세의 특성을 정확히 파악할 필요가 있다. 여기에서는 결정적 추세모형(deterministic trend model; DT)와 확률추세모형(stochastic trend model; ST)을 설명하기로 한다. 예를 들어, 시계열 \\(x_t\\)가 \\(\\alpha + \\beta t\\)의 선형시간추세를 가지고 있을 때 이 추세로부터의 편차가 1-차 자기회귀모형을 따르는 경우를 생각해 보자. \\[ x_t-\\alpha - \\beta t = \\phi(x_{t-1}-\\alpha-\\beta(t-1))+a_t, \\quad a_t \\sim N(0,\\sigma^2_\\alpha) \\] 단, t는 차분이 1인 시간 인덱스를 나타낸다. (1,2,3 …) 위 식은 다음과 같이 표현할 수 있다. \\[ x_t = [(1-\\phi)\\alpha + \\phi \\beta]+(1-\\phi)\\beta t + \\phi x_{t-1} + a_t \\\\ = \\alpha^* + \\beta^* t + \\phi x_{t-1} + a_t \\] \\(z_t = x_t - \\alpha - \\beta t\\)라고 정의했을 때 식을 다음과 같이 변경할 수 있을 것이다. \\[ z_t = \\phi^t z_0 + \\sum^{t}_{i-1}\\phi^{t-i}a_i \\] \\(z_0\\)은 임의의 초기값이다. 만일 \\(|\\phi|&lt;1\\)이면 초기값 \\(z_0\\)의 영향은 점차 감소할 것이며 최근의 충격은 과거의 충격보다 \\(z_t\\)에 더 큰 영향을 미칠 것이다. 그러나 특정시점에서의 충격은 장기적으로 사라지게 될 것이다. 즉, DT모형에서는 \\(x_t\\)가 이의 평균 \\(\\alpha + \\beta t\\)로 회귀하는 특성을 갖게 된다. 시간추세모형은 물론 시간에 대해서 선형일 필요는 없다. 예를 들어, 성장곡선모형에 많이 사용되는 Gompertz 성장곡선모형은 다음과 같은 비선형 추세를 갖는다. \\[ x_t = \\alpha exp ^{-\\beta exp(-\\gamma t)}+ a_t, \\quad a_t \\sim N(0,\\sigma^2_a) \\] 만약 \\(\\phi = 1\\)이면 다음과 같은 확률보행과정(random walk process)이 된다. \\[ x_t = \\beta + x_{t-1} + a_t \\] 이 경우 \\(z_t = z_0 + \\sum^{t}_{i=1}a_i\\)가 되며 \\(x_t\\)는 다음과 같이 표현할 수 있다. \\[ x_t = x_0 + \\beta t + \\sum^t_{i=1} a_i \\] 식에서 \\(\\sum^t_{i=1} a_i\\) 항을 확률 추세(stochastic trend)라고 하고 이 때의 \\(x_t\\)를 ST시계열이라고 한다. 확률추세항을 보면 \\(x_t\\)를 왜 적분과정이라고 부르는지 알 수 있다. 확률보행과정은 한 번 차분하면 안정적이기 때문에 1-차 적분과정이라고 부르고 기호로는 보통 I(1)로 표시한다. ST모형에서는 현재뿐만 아니라 아주 오래 전의 충격도 동일하게 \\(x_t\\)에 영원한 영향을 미친다. 물론 시간추세항 \\(\\beta t\\)가 포함되어 있으나 \\(\\beta\\)의 크기가 \\(\\sigma^2_\\alpha\\) 보다 상대적으로 작으면 \\(x_t\\)의 움직임은 주로 확률추세의 의해 좌우되며 시간추세에서 벗어난 경우 그 상태에서 상당기간 머무는 특성이 있다. 만일 \\(\\beta\\)가 0이면 \\(x_t\\)는 어떠한 평균우로도 회귀하지 않을 수 있다. DT모형의 평균회귀성향과 ST모형의 표류성향은 장기예측에 있어서 후자의 정확도가 훨씬 떨어질 것임을 시사하고 있다. 우리가 보통 분석하고 예측하는 금융 및 경제 시계열들은 대부분 I(1) 과정이다. 확률 추세를 가지고 있는 임의의 시계열이 있다고 할 때 두드러지는 특성 중 하나는 이의 AR 표현식이 적어도 하나의 (1-L)항을 갖는다는 것이다. 즉, \\[ \\phi_p(L) = (1-\\phi_1 L - \\cdots - \\phi_p L^P) \\\\ = (1-\\alpha_1 L - \\cdots - \\alpha_{p-1}L^{p-1})(1-L) \\\\ = \\phi_{p-1}(L)(1-L) \\] 만약 위의 AR(p)모형이 I(1)과정이라면 \\[ \\phi_p(1) = 1-\\phi_1 - \\cdots - \\phi_p = 0 \\] 이 성립한다. 이를 바탕으로 \\(x_t\\)가 안정적 AR(2)과정인지 아니면 확률 추세를 갖는 I(1)과정인지 검정할 수 있는 방법이 있음을 알 수 있다. 즉, \\(\\phi_1 + \\phi_2 &lt; 1\\) 또는 \\(\\phi_1 + \\phi_2 = 1\\)를 검정하면 될 것이다. 그러나 적분된 자료를 분석하는 경우 문제는 유한한 표본을 가지고 \\(\\phi\\)를 추정해야 하며 이 때 적용하는 통계적 추론 절차는 전통적인 t-검정과는 차이가 있다는 점이다. 이러한 검정방법을 다루는 분야를 보통 단위근 검정(unit root test)이라고 부른다. 4.3 Dickey-Fuller 단위근 검정 시계열에 단위근이 있는지를 검정하는데 왜 일반적인 통계적 추론절차를 사용할 수 없는지를 이해하기 위하여 다음과 같이 단순한 AR(1)모형에 OLS를 적용하고 회귀계수에 대한 가설검정을 수행하는 경우를 생각해보자. \\[ x_t = \\alpha x_{t-1} + u_t, \\quad u_t \\sim i.i.d. (0,\\sigma^2_u) \\] 만일 위의 식에서 계수 \\(\\alpha\\)의 참값이 절대값으로 1보다 작은 경우 일반적인 점근분포이론(asymptotics)에 의하면 OLS추정량 \\(\\hat{\\alpha}\\)은 다음과 같은 점근적 정규분포를 갖는다. \\[ \\sqrt{T}(\\hat{\\alpha}-\\alpha) \\xrightarrow[]{a} N(0, [\\sigma^2_u/(1-\\alpha^2)]) = N(0, 1- \\alpha^2) \\] 단, 꺾은 괄호 안의 값은 AR(1)과정의 특성에서 배운 것처럼 \\(x_t\\)과정의 분산에 불과하다. 만일 \\(|\\alpha|&lt;1\\)이면 통상의 통계적 검정절차를 따라 t-검정을 수행할 수 있다. 그러나 귀무가설이 \\(H_0:\\alpha = 1\\), 즉 \\(x_t\\)가 I(1)인 적분과정이면 귀무가설하에서 식의 분산은 0이 된다. 즉, \\(\\hat{\\alpha}\\)의 점근분포는 다음과 같이 0이라는 한 점으로 모두 귀착되게 된다. \\[ \\sqrt{T}(\\hat{\\alpha} - 1 ) \\xrightarrow{a} 0 \\qquad \\cdots (1) \\] 따라서 우리가 관심이 있는 귀무가설 \\(H_0 : \\alpha = 1\\)하에서 의미가 있는 통계적 가설검정을 할 수 없는 상황이 발생하는 것이다. 이러한 경우 Dickey와 Fuller(이하 DF로 약칭)는 단위근 검정을 위하여 다음과 같은 통계량을 계산하고 Fuller(1976)의 table을 사용하여 가설검정 할 것을 권고하고 있다. (표를 직접적으로 사용하지 않을 것이기에 첨부하지 않음) \\[ T(\\hat{\\alpha}-1) = T^{-1} \\sum^{T}_{t=1}x_{t-1}(x_t-x_{t-1})/T^{-2} \\sum^{T}_{t=1}x^2_{t-1} \\qquad \\cdots (2)\\\\ t = (\\sum x^2_{t-1})^{1/2}(\\hat{\\alpha}-1)/S \\qquad \\cdots (3) \\] 단, \\(S^2 = T^{-1}\\sum(x_t-\\hat{\\alpha}x_{t-1})^2\\)이고 \\(\\hat{\\alpha}\\)는 OLS추정량을 나타낸다. 즉, \\(\\hat{\\alpha} = \\frac{\\sum^{T}_{t=1}x_{t-1}x_t}{\\sum^{T}_{t=1}x_{t-1}^2}\\) 식 (1)에서 \\(T(\\hat{\\alpha}-1)\\)의 1은 단위근 귀무가설하에서의 \\(\\alpha\\)값이고 식 (3)에서 등호 왼쪽의 t는 통상의 t-통계량을 나타낸다. DF에 의하면 식 (1)과 같이 \\(\\sqrt{T}\\)를 곱하는 대신 식 (2)처럼 \\(T\\)를 곱하면 통계량 \\(T(\\hat{\\alpha}-1)\\)의 분산은 0으로 모두 귀착하지 않고 어떤 극한분포(limiting distribution)가 존재한다는 것이다. 이 극한분포를 이용하여 \\(\\alpha\\)가 1인가 하는 귀무가설을 검정할 수 있드는 것이 DF 단위근 검정의 주요 내용이다. 다만, \\(T(\\hat{\\alpha}-1)\\)의 극한분포는 좌우대칭적인 분포가 아니라 음의 비대칭성(skewed to the left)을 띈다. DF-검정은 다음과 같은 식에서 \\(\\rho=0\\)인지를 검정하는 것과 같다. \\[ \\Delta x_t = \\mu + \\rho x_{t-1} + \\beta \\cdot (t-(T/2))+u_t \\] 그러나 원래의 자료는 보다 일반적인 AR(p)모형에서 생성된 경우를 생각할 수 있다. p-차의 AR과정에 단위근이 있으면 표현식에는 (p-1)-개의 \\(\\Delta x_t\\)의 래그항들이 나타나게 된다. ‘확장DF-검정’(augmented DF 검정) 또는 줄여서 ‘ADF-검정’은 누락된 AR 파라미터의 효과를 다음과 같은 모형설정을 통하여 고려하고 있다. \\[ \\Delta x_t = \\mu + \\rho x_{t-1} + \\beta (t-(T/2)) + \\delta_1\\Delta x_{t-1} + \\cdots + \\delta_{p-1}\\Delta x_{t-p+1} + u_t \\] 이 경우에도 귀무가설은 \\(H_0 : \\rho = 0\\) 또는 \\(H_0 : \\rho = 0, \\beta = 0\\)이다. 물론 ARMA(p,q) 모형은 적절한 AR모형으로 근사할 수 있으므로 \\(\\Delta x_{t-i}\\)항들을 충분히 오른쪽에 추가함으로써 검정할 수 있게 된다. Said and Dickey(1984)는 p를 충분히 크게 설정할 것을 권하고 있다. 실증 분석에서는 \\(\\Delta x_{t-i}\\) 추가해 가면서 유의적인 항이 어디까지인가를 살펴보고 p를 정하기도 한다. 4.3.1 예제) KOSPI 주가지수의 ADF-검정 ADF검정을 이용하여 자연대수를 취한 KOSPI 주가지수에 단위근이 존재하는지 살펴보자. 기간은 2019/01/05부터 2021/12/28까지 이다. kospi = yf.download(&quot;^KS11&quot;,start=&quot;2019-01-05&quot;, end=&quot;2021-12-28&quot;) ## [*********************100%***********************] 1 of 1 completed plt.cla() kospi[&quot;Adj Close&quot;].plot.line() plt.show() kospi ## Open High ... Adj Close Volume ## Date ... ## 2019-01-07 2034.239990 2048.060059 ... 2037.099976 440200 ## 2019-01-08 2038.680054 2042.699951 ... 2025.270020 397800 ## 2019-01-09 2034.189941 2068.229980 ... 2064.709961 386200 ## 2019-01-10 2065.729980 2072.810059 ... 2063.280029 382900 ## 2019-01-11 2070.360107 2076.989990 ... 2075.570068 380100 ## ... ... ... ... ... ... ## 2021-12-21 2981.669922 2984.560059 ... 2975.030029 410500 ## 2021-12-22 2993.500000 3000.790039 ... 2984.479980 461400 ## 2021-12-23 2998.020020 3000.699951 ... 2998.169922 483300 ## 2021-12-24 3009.479980 3025.770020 ... 3012.429932 537500 ## 2021-12-27 3013.939941 3017.310059 ... 2999.550049 475000 ## ## [736 rows x 6 columns] from statsmodels.tsa.stattools import adfuller def adf_test(timeseries): print(&quot;Results of Dickey-Fuller Test:&quot;) dftest = adfuller(timeseries, autolag=&quot;AIC&quot;) dfoutput = pd.Series( dftest[0:4], index=[ &quot;Test Statistic&quot;, &quot;p-value&quot;, &quot;#Lags Used&quot;, &quot;Number of Observations Used&quot;, ], ) for key, value in dftest[4].items(): dfoutput[&quot;Critical Value (%s)&quot; % key] = value print(dfoutput) adf_test(kospi[&quot;Adj Close&quot;]) ## Results of Dickey-Fuller Test: ## Test Statistic -0.768964 ## p-value 0.828069 ## #Lags Used 2.000000 ## Number of Observations Used 733.000000 ## Critical Value (1%) -3.439303 ## Critical Value (5%) -2.865491 ## Critical Value (10%) -2.568874 ## dtype: float64 def adf_test_by_21(timeseries, maxlag): #none ResultsStore print(&quot;Results of Dickey-Fuller Test:&quot;) dftest = adfuller(timeseries, maxlag=maxlag, autolag=&quot;AIC&quot;, regresults = True) dfoutput = pd.Series( dftest[0:2], index=[ &quot;Test Statistic&quot;, &quot;p-value&quot;, ], ) for key, value in dftest[2].items(): dfoutput[&quot;Critical Value (%s)&quot; % key] = value print(dfoutput) print(dftest[3].resols.summary()) adf_test_by_21(kospi[&quot;Adj Close&quot;],2) ## Results of Dickey-Fuller Test: ## Test Statistic -0.768964 ## p-value 0.828069 ## Critical Value (1%) -3.439303 ## Critical Value (5%) -2.865491 ## Critical Value (10%) -2.568874 ## dtype: float64 ## OLS Regression Results ## ============================================================================== ## Dep. Variable: y R-squared: 0.008 ## Model: OLS Adj. R-squared: 0.004 ## Method: Least Squares F-statistic: 1.985 ## Date: 일, 09 10 2022 Prob (F-statistic): 0.115 ## Time: 20:11:16 Log-Likelihood: -3498.2 ## No. Observations: 733 AIC: 7004. ## Df Residuals: 729 BIC: 7023. ## Df Model: 3 ## Covariance Type: nonrobust ## ============================================================================== ## coef std err t P&gt;|t| [0.025 0.975] ## ------------------------------------------------------------------------------ ## x1 -0.0017 0.002 -0.769 0.442 -0.006 0.003 ## x2 0.0128 0.037 0.348 0.728 -0.060 0.085 ## x3 0.0853 0.037 2.314 0.021 0.013 0.158 ## const 5.3354 5.547 0.962 0.336 -5.555 16.226 ## ============================================================================== ## Omnibus: 47.097 Durbin-Watson: 2.000 ## Prob(Omnibus): 0.000 Jarque-Bera (JB): 185.653 ## Skew: -0.056 Prob(JB): 4.85e-41 ## Kurtosis: 5.463 Cond. No. 1.32e+04 ## ============================================================================== ## ## Notes: ## [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. ## [2] The condition number is large, 1.32e+04. This might indicate that there are ## strong multicollinearity or other numerical problems. 4.4 필립스-페론(Phillips-Perron) 단위근 검정 DF-검정에서는 오차항 \\(u_t\\)가 i.i.d. 정규분포한다고 가정한다. 그러나 많은 금융-경제시계열의 오차항 \\(u_t\\)는 오히려 이분산 특성을 가지고 있고 자기상관이 있는 경우도 있을 것이다. Phillips(1987)와 Perreon(1988)은 \\(x_t\\)의 확률 오차항이 약종속성(weakly dependent)을 띄거나 이분산성을 지닌 것으로 생각되는 경우 사용할 수 있는 비모수적 단위근 검정방법을 제안하였다. 즉, 확률 오차항에 대해 정규성이라는 어떤 강한 가정을 하지 않고자 하는 경우 귀무가설 \\(\\alpha = 1\\)을 검정하기 위하여 Phillips는 다음의 z-통계량을 계산할 것을 제안하였다. \\[ z(\\hat{\\alpha}) = T(\\hat{\\alpha}-1) - \\frac{1}{2}(S^2_{Tl}-S^2_u)/(T^{-2}\\sum x^2_{t-1}) \\\\ z(t_{\\hat{\\alpha}}) = (\\sum x^2_{t-1})^{1/2}(\\hat{\\alpha}-1)/S_{Tl} - \\frac{1}{2}(S^2_{Tl}-S^2_u)[S_{Tl}(T^{-2}\\sum x^2_{t-1})^{1/2})]^{-1} \\] 이때 \\(S^2_u, S^2_{Tl}\\)은 각각 다음과 같은 모수의 표본통계량을 나타낸다. \\[ \\sigma^2_u = \\lim_{T\\rightarrow \\infty} T^{-1} \\sum ^T_{t=1} E(u^2_t) \\\\ \\sigma^2 = \\lim_{T\\rightarrow \\infty} E(T^{-1}S^2_T), \\qquad S_T = \\sum^T_{i=1} u_i \\] 이 통계량들의 차이를 구체적으로 비교해 보기 위하여 다음과 같이 \\(u_t\\)가 MA(1)과정인 예를 들어보자. 즉, \\(u_t = a_t + \\theta a_{t-1}, \\ a_t \\sim i.i.d. (0,\\sigma^2_a)\\)이다. 이 경우 \\[ \\sigma^2_u = \\lim_{T\\rightarrow \\infty} T ^{-1}\\sum^T_{t=1} E(u^2_t)= (1+\\theta^2)\\sigma^2_a \\\\ \\sigma^2 = \\lim_{T\\rightarrow \\infty} E(T^{-1}S^2_T) = (1+\\theta)^2\\sigma^2_a \\] 따라서 \\(\\theta = 0\\), 즉 \\(\\alpha_t\\)가 DF의 경우와 같이 백색잡음이면 \\(\\sigma^2_u = \\sigma^2 = \\sigma^2_a\\)임을 알 수 있다. \\[ S^2_u = T^{-1} \\sum (x_t - \\hat{\\alpha} x_{t-1})^2 \\\\ S^2_{Tl} = T^{-1} \\sum^T_{t=1} E(u^2_t) + 2 T^{-1} \\sum^{T-1}_{\\tau=1} \\sum^{T}_{t=\\tau+1} E(u_t, u_{t-\\tau}) \\qquad \\cdots (1)\\\\ = T^{-1} \\sum^T_{t=1} \\hat{u}^2_t + 2 T^{-1} \\sum^{T-1}_{\\tau=1} \\sum^{T}_{t=\\tau+1} \\hat{u}_t \\hat{u}_{t-\\tau} \\qquad \\cdots (2) \\\\ = T^{-1} \\sum^T_{t=1}\\hat{u}^2_t + 2 T^{-1} \\sum^l_{\\tau=1}(1-\\frac{\\tau}{l+1})\\sum^{T}_{t=\\tau+1}\\hat{u_t}\\hat{u_t}_{-\\tau} \\qquad \\cdots (3) \\] 위 식 (2)을 살펴보면 오차항 곱들의 기대값 대신 OLS 잔차항을 사용함을 알 수 있다. 이를 ‘Hansen-Hodrick(1980) 추정량’이라고도 부른다. 그러나 실증분석에서 식 (2)의 HH 추정량 계산 방식을 사용하여 \\(S^2_{Tl}\\)을 계산하면 이것이 음의 값을 취하는 경우가 종종 있다. 따라서 항상양의 값을 갖고 일차추정량인 \\(S^2_{Tl}\\)를 구하기 위하여서는 식 (3)과 같이 첫 번째 합 기호를 특정 래그 \\(l\\)에서 단절하고 \\(\\tau\\)-차 공분산 \\(\\hat{u_t}\\hat{u_t}_{-\\tau}\\) 항에 일정한 가중치를 부여하게 된다. 식 (3)에서는 ‘바틀렛 가중치’(Bartlett’s window) \\(w(\\tau, l) = 1 - \\tau/(l+1)\\)을 사용하고 있고 이러한 방법을 ’Newey-West(1987) 일치추정량’이라고 부른다. 위 식들을 바탕으로 표본통계량을 구했을 때 식의 z-통계량의 극한분포는 Phillips(1987)의 정리에 의하면 다음과 같다. \\[ z(\\hat{\\alpha}) \\Rightarrow (\\frac{1}{2})[W(1)^2 - (\\sigma^2_u / \\sigma^2)]/\\int^1_0 W(t)^2dt \\\\ z(t_{\\hat{a}}) \\Rightarrow (\\sigma/2\\sigma_u)[W(1)^2 - (\\sigma^2_u/\\sigma^2)]/[\\int^1_0 W(t)^2dt]^{1/2} \\] 이들 극한분포는 앞에서 본 Dickey-Fuller의 극한분포보다 약간 복잡해 보이지만 동일한 임계값 테이블을 통하여 검정할 수 있다. Newey and West(1987)에 의하면 \\(S^2_{Tl}\\)이 일치추정량이기 위해서는 래그 \\(l(T)\\)가 \\(T\\)보다 느린 \\(T^{1/4}\\)의 비율로 커져야 한다. 즉, \\(l(T)\\sim O(T^{1/4})\\)이다. Schwert(1987)는 \\(l(T) = O(4\\cdot(T/100)^{1/4})\\) 또는 \\(l(T) = O(12\\cdot(T/100)^{1/4})\\)를 제안하고 있다. 따라서 실증분석에서는 \\(l(T)\\)를 충분히 크게 잡아 \\(S^2_{Tl}\\)를 계산하거나 또는 서로 다른 \\(l(T)\\)에 대응하는 \\(S^2_{Tl}\\)을 계산하고 이들로부터의 검정결과가 서로 유사한지를 독자가 판단하도록 하는 것이 보통이다. DF 또는 ADF 검정의 경우와 같이 PP검정의 경우에도 귀무가설과 OLS 추정식에 추세와 표류항의 추가 여부 또는 단일가설인지 또는 결합가설인지에 따라 통계량의 극한분포가 달라진다. 이에 대하여는 Perron(1988) 또는 Banerjee et al.(1994)를 참조하라. 4.4.1 예제) Phillips-Perron을 활용한 Kospi 자료의 단위근 검정 ADF검정과 동일한 데이터를 사용하여 진행한다. lag의 경우 \\(T^{1/4}\\)로 자동으로 설정된다. from arch.unitroot import PhillipsPerron import numpy as np import statsmodels.api as sm pp = PhillipsPerron(kospi[&quot;Adj Close&quot;], lags=None,test_type=&#39;tau&#39;) print(pp.summary()) #test type이 &#39;tau&#39;일 경우 t-stat &#39;rho&#39;일 경우 test based on nobs times the re-centered regression coefficient ## Phillips-Perron Test (Z-tau) ## ===================================== ## Test Statistic -0.807 ## P-value 0.817 ## Lags 20 ## ------------------------------------- ## ## Trend: Constant ## Critical Values: -3.44 (1%), -2.87 (5%), -2.57 (10%) ## Null Hypothesis: The process contains a unit root. ## Alternative Hypothesis: The process is weakly stationary. print(&quot;Alternative hypothesis is :&quot;) ## Alternative hypothesis is : print(pp.alternative_hypothesis) ## The process is weakly stationary. print(&quot;Null hypothesis is :&quot;) ## Null hypothesis is : print(pp.null_hypothesis) ## The process contains a unit root. print() print(&quot;lag : &quot;, pp.lags) ## lag : 20 print(&quot;number of observations : &quot;, pp.nobs) ## number of observations : 735 print() print(&quot;p-value : &quot;, pp.pvalue ) ## p-value : 0.8171579241455434 print(&quot;test - statisic of unit root : &quot;, pp.stat) ## test - statisic of unit root : -0.8066599541369417 print(pp.regression.summary()) ## OLS Regression Results ## ============================================================================== ## Dep. Variable: y R-squared: 0.996 ## Model: OLS Adj. R-squared: 0.996 ## Method: Least Squares F-statistic: 1.688e+05 ## Date: 일, 09 10 2022 Prob (F-statistic): 0.00 ## Time: 20:11:18 Log-Likelihood: -3510.5 ## No. Observations: 735 AIC: 7025. ## Df Residuals: 733 BIC: 7034. ## Df Model: 1 ## Covariance Type: HAC ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## Level.L1 0.9984 0.002 410.896 0.000 0.994 1.003 ## const 5.1605 6.471 0.797 0.425 -7.523 17.844 ## ============================================================================== ## Omnibus: 51.299 Durbin-Watson: 1.973 ## Prob(Omnibus): 0.000 Jarque-Bera (JB): 198.707 ## Skew: -0.162 Prob(JB): 7.10e-44 ## Kurtosis: 5.527 Cond. No. 1.32e+04 ## ============================================================================== ## ## Notes: ## [1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 20 lags and without small sample correction ## [2] The condition number is large, 1.32e+04. This might indicate that there are ## strong multicollinearity or other numerical problems. 4.5 유사회귀분석 적분과정을 따르는 변수를 사용하여 실증분석을 하는 경우 어떠한 문제점이 있을 수 있는지 다음과 같은 Granger and Newbold(1974)의 유사회귀분석(spurious regression)의 경우를 예로 들어보자. \\[ y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u_t}, \\qquad t = 1,2,\\cdots,T \\] 여기서 \\(y_t\\)와 \\(x_t\\)는 서로 독립인 확률보행과정, 즉 I(1)이라고 가정하자. \\[ y_t = y_{t-1} + v_t, \\ v_t \\sim i.i.d.(0,\\sigma^2_v), \\ t=1,2,\\cdots,T \\\\ x_t = x_{t-1} + w_t, \\ w_t \\sim i.i.d. (0,\\sigma^2_w), \\ t=1,2,\\cdots,T \\] 단 \\(Cov(v_t,w_t) = 0\\)이다. 즉, 위의 식은 서로 상과없는 두 개의 확률보행과정을 사용하여 회귀분석을 진행한 것이다. 따라서 \\(\\beta\\)와 t-통계량, 그리고 \\(R^2\\)은 기무가설하에서 0이어야 한다. OLS 추정량 $과 기타 통계량의 극한분포를 구하면 다음과 같다. \\[ \\hat{\\beta} = \\frac{\\sum y_t (x_t - \\bar x)}{\\sum(x_t - \\bar x)^2} \\\\ = \\frac{T^{-2} \\sum y_t x_t - T^{-1} \\bar y \\bar x}{T^{-1} \\sum (x_t- \\bar x)^2} \\\\ \\Rightarrow \\frac{\\sigma_v\\sigma[\\int^1_0 V(t)W(t)dt - \\int^1_0V(t)dt \\int^1_0 W(t)dt]}{\\sigma^2_w[\\int^1_0W(t)^2dt - {\\int^1_0 W(t)dt}^2]} \\\\ = (\\sigma_v/\\sigma_w) \\cdot \\zeta \\] 그러므로 \\(\\hat{beta}\\)는 \\(T \\rightarrow \\infty\\)함에 따라 비함몰(non-degenerate) 극한분포를 가진다. 또한 별도로 예시하지는 않았지만 \\(\\hat{a}\\)의 극한분포는 \\(T\\rightarrow \\infty\\) 함에 따라 확대된다. 그리고 통상의 t-통계량들, 즉 \\(t_\\alpha\\), \\(t_\\beta\\)는 극한 분포 자체가 존재하지 않는다. 실제로 \\(t_\\alpha\\)와 \\(t_\\beta\\)의 분포는 \\(T\\rightarrow\\infty\\)함에 따라 확대되어 통상의 유의성 검정을 위한 점근적 임계치가 존재하지 않는다.그러나 Phillips는 올바르게 교정한 표준화통계량,즉 \\({t_\\beta}^\\prime = t_\\beta / \\sqrt{T}\\)는 다음과 같은 극한 분포를 가진다고 하였다. \\[ T ^ { -1/2 } \\cdot t_\\beta = \\mu/\\nu^{1/2} \\] 단, \\[ \\mu = [\\int^1_0 V(t)W(t)dt - \\int^1_0 V(t)dt \\int^1_0 W(t)dt] \\\\ \\nu = [\\int^1_0 V(t)^2dt - (\\int^1_0V(t)dt)^2][\\int^1_0 W(t)^2dt - (\\int^1_0W(t)dt)^2] - [\\int^1_0 V(t)W(t)dt - \\int^1_0 V(t)dt \\int^1_0 W(t)dt]^2 \\] Phillips에 의하면 유사회귀식의 경우 더빈-왓슨 통계량 (DW)은 함몰분포를 갖는다. \\[ DW \\xrightarrow{L} 0 \\] 또한 \\(R^2\\)는 \\(T \\rightarrow \\infty\\) 함에 따라 비함몰분포를 갖는다. 즉, \\[ R^2 = \\frac{\\zeta^2[\\int^1_0W(t)^2dt - (\\int^1_0 W(t)dt)^2]}{\\int^1_0V(t)^2dt - (\\int^1_0V(t)dt)^2} \\] 이상의 결과를 요약하면 서로 관련이 없는 I(1) 변수들끼리 회귀분석하면 회귀계수는 보통 0과 다른 유의적인 값을 취하고 \\(R^2\\)는 높으며 계산된 잔차항은 높은 양의 자기상관을 보여 마치 두 변수가 서로 관계가 있는 것처럼 보이는 위험이 있다는 것이다. 이러한 유사회귀분석의 경우 두 변수의 수준이 아니라 이들을 차분한 뒤 회귀분석하면 두 변수 사이에 관계가 없는 것으로 옳게 나온다. 4.6 단위근이 있는 시계열의 유사추세 및 사이클 Nelson은 다음과 같은 동적 선형모형(dynamic linear models; DLM)에서 Dickey-Fuller 현상이 어떻게 작용할 수 있는지를 연구하였다. \\[ x_t = \\tau_t + c_t \\\\ \\tau_t = \\beta_{t-1} + \\tau_{t-1} + w_t \\\\ \\beta_t = \\beta_{t-1} + u_t \\\\ c_t = \\phi(L)^{-1}v_t \\] 단, \\(w_t, u_t\\) 그리고 \\(v_t\\)는 서로 독립이고 각각의 분산이 \\(\\sigma^2_w, \\sigma^2_u\\) 그리고 \\(\\sigma^2_v\\)인 정규분포 백색잡음이다. 안정적 부분인 \\(c_t\\)는 AR(2)라고 가정하자. 만일 \\(x_t\\)가 대수를 취한 주가이면 추세부분인 \\(\\tau_t\\)는 내재가치를, 그리고 안정적 부분인 \\(c_t\\)는 투자심리 부분을 나타낸다. 만일 \\(x_t\\)가 대수를 취한 GDP이면 \\(\\tau_t\\)는 확률적 추세(공급충격에 의하여 장기적으로 결정되는 부분)를, 그리고 안정적인 부분인 \\(c_t\\)는 순환변동 (통화 및 재정정책에 의하여 일시적으로 영향을 받는 부분)을 나타낸다고 할 수 있다. 제 2차 세계대전 후 미국의 실질 GNP 자료를 이용하여 Watson(1986)은 위의 식을 상태-공간모형으로 전환한 뒤 칼만필터 연산식을 사용하여 다음과 같은 추정 결과를 얻었다. $$ \\ x_t = t + c_t\\ t = 0.0008 + {t-1} + w_t, w = 0.0057 \\ c_t = 1.501 c{t-1} - 0.577c{t-2} + v_t, _v = 0.0076 \\ 대수우도함수값 = 294.42,  S.E. = 0.0099 $$ 단, S.E.는 예측오차의 표준편차를 나타낸다. 여기서 순환변동부분을 다음과 같이 표현해보자. \\[ c_t = (\\phi_1 + \\phi_2)c_{t-1} + \\phi_2(c_{t-1}- c_{t-2}) + v_t \\\\ = 0.924c_{t-1} + 0.577(c_{t-1} - c_{t-2}) + v_t \\] 만일 \\((\\phi_1 + \\phi_2)\\)의 참값이 1이면 최소자승법에 의한 이의 추정량은 영의 방향으로 편의를 보이는 경향이 있다. 즉, Nelson and Kang(1981)의 연구결과에 의하면 \\(\\rho = \\phi_1 + \\phi_2\\)의 참값이 1일때 \\(\\hat{\\rho} = \\hat{\\phi_1} + \\hat{\\phi_2}\\)의 기대값은 0.93(또는 T가 큰 경우 \\(\\approx 1 - 10/T\\)로 계산함)이다. Watson의 경우 T는 144이다. 그러므로 안정적인 과정으로 \\(c_t\\)를 추정한 Watson의 결과는 실제로 \\(\\rho = 1\\)이고 추세가 다음과 같이 단순한 선행시간추세를 갖는 모형을 추정한 경우의 얻게 되는 편의와 매우 유사함을 알 수 있다. \\[ \\tau_t = \\tau_{t-1} + \\beta \\quad (\\sigma_w = 0) \\] 즉, \\(\\rho = 1\\)과 \\(\\sigma_w = \\sigma_u = 0\\)을 가정하고 정리하면 Watson의 경우는 다음과 같은 추세안정적인 모형을 상태-공간모형을 이용하여 추정한 것과 같게 된다. \\[ x_t = \\rho x_{t-1} + \\beta t + \\phi(c_{t-1} - c_{t-2}) + v_t \\] 따라서 참값이 \\(\\rho = 1\\)임에도 이의 OLS 추정치가 1보다 작게 되는 ’Dickey_Fuller현상’이 상태-공간모형에 의하여 추정하는 경우에 발생할 수 있다는 것이다. 상태-공간모형에서 이러한 유사추세 및 사이클(spurious tredn and cycle)이 발생할 수 있는지를 실증적으로 규명하기 위하여 Nelson은 사이클이 전혀 없는 확률보행과정을 시뮬레이션하였다. 그리고 이 자료를 이용하여 추정환 결과 상태-공간모형은 전형적으로 추세부분을 원래보다 매우 스무드한 것으로 추정하며(즉,\\(\\sigma_w\\)가 매우 작게 추정됨), 자료 변동의 대부분이(그릇되게) 자기상관이 매우 높은 사이클로부터 비롯하는 것처럼 나타나는 경향이 있음을 발견하였다. 또한 유사사이클이 추정해내는 모형이 자료생성과정(즉, 확률보행과정)의 경우보다 통상의 기준에서 볼 대 대수우도함수값이 유의적으로 높은 것으로 나타났다. 요약하면 단위근이 있는 자료를 사용하여 이를 확률보행과정 추세와 안정적 사이클로 분해되는 경우 유사추세와 유사사이클을 추정한 것인지 또는 실제로 어떤 것을 발견한 것인지 결론을 내릴 때 특별한 주의가 필요하다는 것이다. 4.7 시간추세 안정적 시계열과 차분안정적 시계열의 선택문제 단위근이 있는 시계열은 다음의 예와 같이 차분하면 안정적인 계열이 된다. \\[ \\Delta x_t = \\mu + a_t \\] 즉, ST 시계열은 차분함으로써 추세를 제거할 수 있다. 반면에 식에 예시한 DT 시계열은 선형시간추세를 제거한 후 안정적인 계열이 된다. \\[ x_t - \\alpha - \\mu t = u_t \\] 8.1절에서 설명한 것처럼 확률보행과정은 반복 대입을 통해 다음과 같이 다시 표현할 수 있으며 추세안정적 시계열과 차분안정적 시계열은 서로 유사성이 있음을 알 수 있다. \\[ x_t = x_0 + \\mu \\cdot t + \\sum^t_{i=1} a_t = \\alpha + \\mu \\cdot t + u_t \\] 여기서 \\(x_0\\)는 임의의 초기값을 나타낸다. 위의 두 식의 표현의 유사성에도 불구하고 이들의 오차항 \\(u_t\\)의 특성은 확연히 다르다. 즉, 후자의 경우는 과거 및 현재의 오차항의 합으로 표현되어 있어 \\(u_t\\)의 분산은 \\(t\\sigma^2_a\\)으로 시간이 경과함에 따라 점차 증가하게 된다. 이러한 차이점은 장기예측의 경우 확연하다. 전자의 경우 장기예측치는 현재 또는 과거의 오차항 값에 관계없이 항상 \\(\\alpha + \\mu t\\)인 반면 후자는 과거부터 현재까지 누적된 오차항 (또는 이벤트)에 영향을 받는다. Nelson and Kang(1981,1984)은 자료생성과정이 차분안정적 과정일 때 이를 시간추세 안정적과정으로 잘못 간주하고 분석하는 경우 어떠한 결과가 초래되는지를 집중분석하였다. 이들의 연구결과를 요약하면 다음과 같다. 표류항 \\(\\mu\\)가 없는 확률보행과정을 시간에 대하여 OLS 추정하면 \\(R^2\\) 값이 표본의 크기에 관계없이 약 0.44가 된다. 표류항이 있는 경우에 \\(R^2\\) 값은 표본의 크기가 증가함에 따라 증가하며 점차 1.0에 근사한다. 확률보행과정을 시간에 대하여 OLS 추정한 후 구한 잔차항의 분산은 표본의 크기가 표류항의 크기에 관계없이 평균적으로 \\(\\Delta x_t = \\mu + a_t\\)의 \\(\\sigma^_a\\)의 약 14%에 불과하다. 확률보행모형으로부터 (그릇되게) 시간추세를 제거한 후 얻은 잔차항의 표본자기상관계수의 평군값은 표본의 크기 T의 함수이며 래그 1에서 대략 (1-10/T)이다. 물론 원래의 확률보행모형의 오차항은 백색잡음이므로 이러한 자기상관들은 순전히 ‘통계적 허상’(statistical artifiact)이다. SACF는 약 (2/3)T의 주기로 순환한다. 따라서 시간추세 자료는 (그릇되게) 유사장기사이클(suprious long cycle)을 보인다. 통상의 t-통계량을 사용하여 시간추세의 회귀계수 \\(\\mu\\)가 0이라는 귀무가설을 검정하는 경우 표본의 크기가 100이고 5% 유의수준을 적용하면 귀무가설이 사실임에도 이를 87% 기각하였다. 따라서 차분안정적인 시계열을 추세안정적인 시계열로 착각하는 경우 매우 심각한 오류를 초래할 수 있다는 것이다. 그러면 추세안정적인 자료를 실수로 차분하여 사용하면 어떠한 결과가 초래될 것인가? Plosser and Schwert(1977,1978)의 연구결과에 의하면 이 경우의 오류가능성은 앞의 경우에 비해서는 그리 크지 않다는 것이다. 따라서 실증분석에 있어서는 추세안정적인지 또는 차분안정적인지 불분명한 경우에는 후자로 가정하는 것이 덜 위험하다고 볼 수 있다. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
